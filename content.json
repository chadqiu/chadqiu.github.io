{"meta":{"title":"chadqiu","subtitle":"","description":"","author":"John Doe","url":"http://chadqiu.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2024-11-26T16:26:22.003Z","updated":"2024-11-26T16:26:22.003Z","comments":false,"path":"/404.html","permalink":"http://chadqiu.github.io/404.html","excerpt":"","text":""},{"title":"关于","date":"2024-11-26T16:26:22.005Z","updated":"2024-11-26T16:26:22.005Z","comments":false,"path":"about/index.html","permalink":"http://chadqiu.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"友情链接","date":"2024-11-26T16:26:22.005Z","updated":"2024-11-26T16:26:22.005Z","comments":true,"path":"links/index.html","permalink":"http://chadqiu.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2024-11-26T16:26:22.006Z","updated":"2024-11-26T16:26:22.006Z","comments":false,"path":"repository/index.html","permalink":"http://chadqiu.github.io/repository/index.html","excerpt":"","text":""},{"title":"分类","date":"2024-11-26T16:26:22.005Z","updated":"2024-11-26T16:26:22.005Z","comments":false,"path":"categories/index.html","permalink":"http://chadqiu.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2024-11-26T16:26:22.005Z","updated":"2024-11-26T16:26:22.005Z","comments":false,"path":"books/index.html","permalink":"http://chadqiu.github.io/books/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-11-26T16:26:22.006Z","updated":"2024-11-26T16:26:22.006Z","comments":false,"path":"tags/index.html","permalink":"http://chadqiu.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"24-12-08 Z哥直播","slug":"24-12-08-Z哥直播","date":"2024-12-09T15:04:40.000Z","updated":"2024-12-14T04:46:02.152Z","comments":true,"path":"6ed5eb4bec80.html","link":"","permalink":"http://chadqiu.github.io/6ed5eb4bec80.html","excerpt":"","text":"下周锦囊根据你提供的内容，似乎你询问的是下周的锦囊内容。从对话内容来看，这位Z哥（可能是直播主）在谈论如何在股市中抓住机会，以及如何避免踏空。他提到下周的主要策略是“等”，即等待市场方向的选择。 具体来说，Z哥建议： 等待市场方向的选择。 四分之一到半仓进入市场，以感知水温和市场变化。 保持耐心，不要急于行动。 Z哥强调了经验和量化标准的重要性，并提到要避免盲目追涨，以免陷入追高的陷阱。 综上所述，下周的锦囊内容似乎是：等待市场方向明确，适量进入市场，保持耐心。 操作建议从上述直播内容中，可以提炼出一些适合当前股票操作的建议。以下是总结的关键点： 1. 保持耐心，等待方向选择 博主观点：当前市场处于窄幅震荡阶段，指数波动较小，机构资金正在逐步入场，但尚未形成明确的上涨趋势。因此，建议投资者不要急于追高，而是耐心等待市场的方向选择。 操作建议：可以适当减少操作频率，避免频繁买卖。如果要参与，建议在市场出现明确的方向突破后再行动，或者逢低买入（如出现B1点位时）。 2. 关注量化标准，尤其是B1点位 博主观点：博主强调了量化标准的重要性，尤其是在右侧交易中，建议关注周线和日线的B1点位。B1点位是博主认为最符合机构做盘逻辑的买点，能够在市场轮动中获得较好的收益。 操作建议：如果你看好某个股票，可以在其出现B1点位时介入，尤其是当该股在调整后再次企稳时。这样可以确保你在成本最低的情况下进入市场，减少风险。 3. 避免追高，尤其在短期快速上涨后 博主观点：博主多次提到，很多股票在短期内快速上涨后，往往会迅速回调，导致追高的投资者被套。因此，建议不要盲目追高，尤其是在市场情绪过热时。 操作建议：对于已经快速上涨的股票，建议不要追涨，而是等待回调后再考虑是否介入。如果手中持有此类股票，可以在高位适当减仓，锁定利润。 4. 关注板块轮动，尤其是新能源车和芯片 博主观点：当前市场的主要机会在于板块轮动，尤其是新能源车和芯片板块。新能源车已经进入了扩大战果的阶段，而芯片板块虽然短期内可能面临调整，但长期来看仍然有较大的发展潜力。 操作建议：可以关注新能源车和芯片板块中的龙头股，尤其是那些业绩稳定、估值合理的公司。对于芯片板块，建议在回调时介入，而不是追高。 5. 控制仓位，避免重仓操作 博主观点：博主反复强调，投资者应该根据自身的认知和经验来控制仓位，避免重仓操作。即使是看好的股票，也不建议一次性满仓买入，而是分批建仓，逐步加码。 操作建议：建议将仓位控制在四分之一到半仓之间，尤其是在市场方向尚未明确的情况下。这样可以在市场波动时有更多的灵活性，既可以抓住机会，又能在不利情况下及时止损。 6. 左侧交易需谨慎，右侧交易为主 博主观点：左侧交易（即抄底）需要非常强的经验和判断力，普通投资者难以把握。相比之下，右侧交易（即在确认上涨趋势后再介入）更为稳妥，适合大多数投资者。 操作建议：尽量避免左侧交易，尤其是在市场底部尚未明确的情况下。右侧交易更为安全，建议在股票或板块出现明确的上涨信号后再介入。 7. 避免短线操作，专注于长线投资 博主观点：博主不建议普通投资者进行短线操作，因为短线交易需要极高的市场敏感度和执行力，普通投资者很难做到。相反，长线投资更符合大多数人的能力和风险承受能力。 操作建议：如果你没有足够的经验和时间来跟踪市场，建议专注于长线投资，选择基本面良好、行业前景广阔的公司，耐心持有，穿越周期。 8. 注意风险控制，设置止损止盈 博主观点：无论是在左侧还是右侧交易，都需要严格设置止损止盈点。即使你看好某个股票，也要做好风险控制，避免因市场波动而导致较大损失。 操作建议：建议为每一笔交易设定明确的止损和止盈点位。例如，当股票下跌超过3-5%时，果断止损；当股票上涨达到预期目标时，及时止盈，锁定利润。 9. 关注政策导向，尤其是国企和央企 博主观点：博主认为，当前市场的机会与政策导向密切相关，尤其是国企和央企的改革和发展。这些公司通常会受益于国家的支持，未来可能会有较大的增长潜力。 操作建议：可以适当关注国有背景的公司，尤其是那些与国家战略相关的领域，如新能源、高端制造等。这些公司在政策支持下，可能会有较好的表现。 10. 保持理性，不要被情绪左右 博主观点：博主多次提醒投资者要保持理性，不要被市场的情绪所左右。无论是踏空还是追高，都是因为投资者的认知不足和情绪波动导致的。 操作建议：不要因为担心踏空而盲目追涨，也不要因为短期亏损而恐慌割肉。保持冷静，按照自己的交易计划执行，避免情绪化操作。 总结：当前市场环境下，建议投资者保持耐心，等待市场的方向选择，避免追高和频繁操作。可以关注新能源车、芯片等板块的龙头股，尤其是在回调时介入。同时，控制好仓位，设置止损止盈点，保持理性，专注于长线投资。 分段内容AI总结[2024-12-08 20-53-05][zettaranc][为什么你总踏不准节奏？].aac 这段文字的内容较为混乱且包含大量口语化的表达及重复信息，难以提取明确的主题和逻辑结构。但从其中的一些片段来看，似乎涉及到了股市分析和个人经历分享等内容。 大致总结如下： 作者讨论了一些关于股市的观点，并强调投资者需要保持冷静的心态。 提到了个人的投资经验，例如某次快速行驶的经历（可能比喻炒股操作）。 分享了一部分有关金融市场的见解，特别是对于某些具体公司的评价。 还有一些零碎的信息涉及到日常生活琐事和其他话题，显得有些离题。 总体上看，这篇文章缺乏清晰的中心思想，更像是即兴发言记录下来的文字材料。如果想要获取更多有用的信息，则建议进一步澄清具体的关注领域并进行更有针对性的问题提问。 根据提供的文本，以下是其中涉及股票及相关市场的干货内容： 关于股市的心态： 要保持冷静，避免盲目追逐热点。 重视长期的投资理念而非短视行为。 具体操作建议： 不要在高位追涨（“不要追高”）。 在低位布局并持有优质标的（例如，“如果能在国庆前后抓住机会，则有可能获得不错的收益。”） 行业分析及推荐方向： 强调关注中国制造能力及其在全球的地位。 提到了某些特定领域的发展潜力：如新能源汽车行业（电动汽车）、先进制造技术等，并暗示投资者应考虑配置此类资产。 个人经验分享： 主播表示自己拥有多年炒股经历且从未错过重大机遇（’我在过去的几十年间未曾踏空任何一波重要的上涨趋势’），以此作为信心来源向听众传达信息。 风险提示： 指出现阶段存在较大不确定性因素影响市场走势，提醒参与者谨慎对待潜在的风险。（虽然这部分表述较为模糊，但从上下文中可以看出主播强调需要警惕当前复杂环境下的各类挑战） 互动环节反馈： 对于部分提问进行了回答，涉及到不同时间段的操作心得总结； 综合评价： 整篇讲话围绕着如何正确看待资本市场变化展开讨论，既包含了宏观层面的战略指导思想，也有微观层次的具体执行方法介绍，旨在帮助普通散户树立正确的理财观念的同时提供实用性的交易技巧参考。 [2024-12-08 21-53-20][zettaranc][为什么你总踏不准节奏？].aac 这段文字记录了一场网络主播（疑似名为“z哥”）与其观众互动的内容摘要，其中涉及大量关于观众发送的照片验证及个人背景讨论。主要内容如下： 观众互动：许多自称是女粉丝的人试图通过发送她们本人及其伴侣的照片来获得认证。 身份确认：主持人经常质疑图片的真实性并尝试判断是否来自真人而非网上的随机图像。 情感状态探讨：有些参与者透露了自己的关系状况，例如不满当前的关系或是寻找新的恋情。 星座话题：多次提及不同星座的性格特征，特别是对于某些特定星座的行为模式进行推测。 总体来看，这场活动似乎是一个娱乐性质较强的在线社交环节，在这里人们可以通过参与游戏的方式增加曝光度甚至找到潜在的对象。然而需要注意的是，由于存在较多虚假信息的可能性，因此需要保持警惕以免受骗。 以下是文中提到的一些关于股市及投资的相关干货： 建立正确的风险意识：文章多次强调，在进行任何投资决策（例如购买股票）之前设定好止损位置的重要性。“你要之前建仓的时候，你就要把止损位设好。”“就是要防患于未然。” 稳健的投资心态：“闷声发大财”，保持谦逊的态度，“不要太张扬”。 明确买卖时机：’你这策略什么时候买，什么时候卖，你要直接要弄好’。 尽管上述信息是从非专业角度出发并掺杂了许多娱乐元素，但在某种程度上反映了投资者应该具备的基本素质——谨慎行事并且做好充分准备。 请注意，以上总结仅供参考，具体操作请根据个人实际情况结合专业的财经资讯做出判断。对于具体的个股推荐或其他详细的操作指导并未提及。 [2024-12-08 22-53-35][zettaranc][为什么你总踏不准节奏？].aac 这段话主要在讨论一个人（Z哥）的文字表达方式和其给人的印象。主要内容可以概括如下： Z哥实际上是学习理科而非文科。 他的文字表述显得生硬且不自然，例如“终于找到了一个”这种措辞让人觉得不太合适或搞笑。 对比之下，更恰当的说法可能是：“你好，我是从Z哥那边来的，终于遇到了一位能打动我的女孩。”这样会更有诚意也更容易引起对方的兴趣。 原始的信息可能因为过于直白而让接收者感到不适甚至产生反感情绪，并可能导致被直接屏蔽掉。 总之，该段落强调了沟通时语言运用的重要性以及不同背景知识如何影响人们的交流效果。 这段文字似乎并没有提到任何具体的关于股票或投资方面的信息。大部分内容看起来像是在讨论某个叫“Z哥”的人的表达方式和措辞，并没有提供实质性的财经或者股市建议。 如果你有更多包含具体股票代码、分析数据或其他有用的投资资讯的文字材料, 我会很乐意帮你提炼关键的信息。请确保提供的文本中确实含有与股票相关的实质性内容以便我能更有效地帮助到您。 [2024-12-08 22-54-47][zettaranc][为什么你总踏不准节奏？].aac 这段文字包含了多个主题的内容，主要包括以下几个方面： 用户互动与抽奖：文中提到多次与粉丝（如“利利”、“amber姑娘”）互动，并进行了几次抽奖活动，赠送鞋子和其他奖品。 星座讨论：详细探讨了一些星座的性格特点及其相互影响，例如天秤座男性与其他特定星座女性的关系建议。 股市投资技巧及理念分享： 强调经验和长期观察的重要性。 提到了板块轮动的概念，即不同的股票或行业会在一段时间内轮流表现良好。 分享了关于如何识别并抓住市场机会的方法，强调耐心等待合适的时机买入而非盲目追求短期收益。 娱乐文化回顾：提及了几十年前流行的歌曲和艺人，对比当下流行文化的变迁。 个人感悟与反思：作者表达了自己的观点，指出大部分人在金融市场中的亏损原因主要是缺乏正确的观念和技术手段；同时也提醒听众要注意风险管理，避免过度自信导致损失扩大。 具体案例解析：举例说明某些股票的操作思路，比如如何利用技术图表判断买卖信号等。 总体而言，这篇文章涵盖了广泛的领域，既有情感上的共鸣又有实用的投资指导信息。 以下是文中提到的一些关于股市投资的重要观点： 了解市场轮动：投资者需懂得市场的运作规律及应对措施。 依靠经验和观察： 经验丰富的投资人通常更能抓住机会并规避风险。 板块轮动的理解与应用： 例如，先关注证券行业（如券商），随后转向互联网金融服务领域；进一步可能会涉及新能源汽车行业等领域。 避免盲目追求热点： 不要在热门题材出现初期急于介入，容易高位买入导致亏损。 控制仓位，谨慎操作： 在当前市场环境下应采取“多看少动”的原则，并且只使用少量的资金试探市场温度，而非全部投入。 警惕短期炒作行为： 短期内股价大幅波动往往是投机性质较强的表现形式，不宜作为长期持有的依据。 重视基本面和技术指标相结合的方法论： 结合公司业绩报告和其他财务数据来进行选股决策的同时，也可以参考技术图表上的支撑阻力位判断买卖时机。 保持耐心等待合适的进场信号: 避免冲动入市造成不必要的损失，而是应当等到价格回落至较低区域后再考虑布局。 风险管理意识不可忽视: 即使是对某些标的物充满信心的情况下也需要设置合理的止损价位以防万一发生不利变动时能够及时退出减少损失程度。 以上信息仅供参考，具体的投资建议请咨询专业的财经顾问。 [2024-12-08 23-54-50][zettaranc][为什么你总踏不准节奏？].aac 这段文字主要讨论了几方面的投资理念与技巧： 市场趋势与轮动：文章强调投资者需关注市场中的“轮动”现象——不同类型的股票（例如低价股）会在不同的时间段表现突出。作者认为抓住这类轮动的关键之一是对市场走势的经验积累。 量化标准的重要性：“B1”(首次出现) 被视为跟踪市场变化的有效工具；买入处于低位的股票有助于降低后续的风险并提高盈利潜力。 理解宏观经济背景及其影响因素：文中提到某些特定时期的主导主题（如房地产），以及它们为何能在较长一段时间内成为市场焦点的原因。此外，还提到了国家战略规划对未来产业发展方向的影响作用。 避免盲目追逐热点：提醒读者不应过分依赖于单一信息来源做出决策，而应当综合考量多种因素后再行动。 耐心等待时机：鼓励投资人要有足够的耐心，找到合适的入场点进行布局，而非急于一时冲动买卖。 风险管理意识：即使找到了潜在的投资标的物也要做好充分的心理准备面对可能出现的各种不利情形，并制定相应的应对措施。 关于具体投资项目的选择：虽然未明确给出任何具体的证券代码作为推荐对象，但仍提供了选择过程中可遵循的一些基本原则指导思想。 总的来说，这篇文章旨在帮助普通股民更好地理解和适应A股市场的运行规律，从而作出更为明智合理的投资决定。 以下是根据您的需求整理的关键干货信息： 关于市场走势： 主力建立共识向上推动股价才是最节省的方式。 市场处于“收敛”期（即波动较小），投资者需谨慎行动。 关于投资心态与行为： 投资者不应频繁追逐热点，以免陷入被动局面。 不要用情绪化决策进行买卖，例如因恐惧而止损离场后再错过回升。 具体的投资技巧与理念： 低价股通常会在一轮行情初期表现较好；随后将转向高价股，尤其是在临近年底至次年初这段时间。 轮动规律：低价股→高价股→高送转概念股。 选股思路: 使用量化工具寻找入场时机，尤其关注K线形态中的’B1’买入信号。 B1是指某个特定的技术图形标志，通常是股价经过一段时间调整后的首次显著上升趋势起点。 风险管理： 在选择标的物时尽量选取具有较强支撑的基础面支持的企业。 宏观经济环境下的投资方向： 关注由国家战略引导的重点发展方向，如新能源汽车行业等。 注意事项： 避免盲目追求热门题材，重视企业内在价值评估。 对于某些特殊类型的股票(如高科技类)，由于涉及专业知识较多，普通投资人应当更加慎重对待。 实战应用实例： 提供了一些实际操作的例子，强调利用量化手段捕捉阶段性底部并耐心等待后续涨幅的重要性。 希望上述提炼的信息对你有所帮助！如果有任何进一步的问题或其他方面的请求，请随时告知。 [2024-12-09 00-54-50][zettaranc][为什么你总踏不准节奏？].aac 这段文字主要讲述了投资股市的一些经验和观点： 产业链分析：作者详细介绍了“果链”（即与苹果供应链有关的企业）的概念，并指出这类企业不仅局限于几个知名的大品牌，还包括许多细分领域的供应商。强调了此类企业的巨大潜力及其背后的庞大资本流动。 新能源汽车产业前景：提到新能源汽车领域在未来5-10年的广阔发展前景，类似于之前的高铁建设热潮。但也警告投资者要注意避免过度炒作导致泡沫破裂的情况发生。 市场规律及轮动现象：阐述了不同类型的板块会在特定时间段轮流成为热点的现象，例如每年都会有类似’果链’的主题出现；某些大型项目则可能会维持多年热度，直到行业发展成熟为止。 具体操作建议： 投资者应具备一定的市场敏感性和前瞻性。 在面对不确定性强的新事物时保持谨慎态度，不宜盲目追逐热门题材。 对于个人投资者而言，则需更加注重风险管理，确保自己的本金安全并逐步积累收益。 总之，文章旨在帮助读者理解复杂的金融市场运作机制，并提供了一些实用的操作指导方针。 以下是文中提到的一些关键干货内容： 关于股市的概念与板块： 果链（苹果供应链）：包含许多细分领域，例如电池隔膜、芯片封装测试、显示屏生产商等。 新能源汽车产业：涵盖25个子行业及约2万个零部件供应商。 投资理念： 投资应注重长线布局而非短线投机：“每年的主题”、“3-5年的中期主题”，避免“一次性”的短暂炒作。 具体行业分析： 苹果产业链：尽管存在竞争压力，但由于庞大的生态系统仍具有吸引力。 电动汽车&#x2F;新能源车：预计在未来一段时间将持续成为热点，并逐步扩展至海外市场。 高速铁路建设：已进入成熟期，不太可能出现爆发性成长。 AI 和 芯片：短期内难以实现显著收益，更多表现为阶段性上涨；需等待技术和市场需求进一步成熟。 选股技巧： 关注龙头企业及其上下游合作伙伴的表现。 注意宏观经济环境变化对公司经营的影响。 风险管理： 控制仓位比例，保持灵活性以便应对不同市场状况。 不要在不了解的情况下盲目追求高额回报。 对于较大金额投资者而言，则应当更加谨慎并分散投资组合降低单一品种集中度过高所带来的潜在风险。 其他要点提示: 市场上不存在永恒不变的成功模式，“适应不断变动的趋势才是王道。” 在面对不确定性和复杂局面时坚持理性思考，避免情绪驱动决策行为发生。 希望以上提炼的信息对你有所帮助！如果有特定方面想要深入了解的地方欢迎继续提问。 [2024-12-09 01-54-50][zettaranc][为什么你总踏不准节奏？].aac 这段文字主要讨论了一些关于证券交易和个人财务规划的经验教训： 炒股策略：作者强调了“右侧”买入的重要性，并指出应在股价回调3-5%后再考虑购买。此外，他还提到不应过度依赖技术图表（例如波浪理论），并提醒投资者需要根据实际情况灵活应对。 风险管理：文中多次提及风控意识，告诫读者不可满仓运作以免遭受重大亏损；同时也提出即使遇到有利时机也不要过于贪婪，适时获利离场所谓’知行合一”。 心态建设：文章中不乏幽默调侃的语言风格，旨在缓解听众紧张的情绪状态，倡导理性看待市场的波动起伏，避免冲动决策导致不必要的经济损失。 长期视角：尽管部分内容涉及短期内的操作技巧，整体而言仍提倡树立正确的金钱观及财富增值理念——即注重基本面研究而非单纯追逐热点题材。 互动交流：文本记录了一场在线问答环节的部分对话摘录，其中包含了许多观众针对自身情况提出的个性化咨询请求及其得到的回答指导。 其他杂项话题：还包括有关择偶交友方面的趣闻轶事以及其他娱乐休闲活动安排等内容，显示出主播试图营造轻松愉快氛围的努力尝试。 综上所述，这篇文章涵盖了金融知识普及、心理素质培养等多个方面，体现了作者希望通过分享经验和见解帮助他人实现稳健成长的愿望。 以下是文中提到的一些关于股票相关的干货： 买入时机： 如果一只股票处于右侧（即股价正在上涨的趋势），并且当日跌幅小于3.5%，特别是如果能够在3%左右企稳并回升，则可能是较好的买入时机。 卖出策略： 短线投资者应在涨幅达到一定程度后及时获利离场。 长期持有策略： 对于某些强势股票，可以在连续几天小幅回调但仍维持在某个支撑价位之上时逐步增加持仓比例。 技术分析要点: 注意每日波动幅度是否超过了3%-3.5%, 超过后需要谨慎对待； 观察K线形态及成交量变化情况； 心态建设： 不断累积经验和知识才能更好地把握市场的脉搏; 重视风险管理而非追求完美避免踏空; 其他提示： 使用专业财经数据库获取宏观经济数据进行辅助决策(例如Wind终端); 指标滞后性: 左侧交易依靠价格变动为主导依据; 右侧交易更多依赖技术指标指引. 请注意上述仅为概括提炼的信息片段，并不代表完整指导方案。实际应用还需根据具体情况进行综合考虑。 [2024-12-09 02-54-51][zettaranc][为什么你总踏不准节奏？].aac 这篇文章包含了多个主题的内容，涉及星座分析、理财建议、人际关系处理等多个方面的讨论。 关于星座：文章首先探讨了几类特定星座（例如狮子座、天蝎座）的职业生涯成功可能性，并指出这几个星座具有较强的执行力。此外，文中提及不同星座组合的关系处理技巧，强调诚实和相互支持的重要性。 金融理财和个人财务管理：作者提供了针对具体理财产品和市场的见解，鼓励投资者保持长期视角并谨慎行事。同时也给出了购房置业的具体建议，特别是关于房产的选择和时机把握。 人际交往指导：涉及到不同类型人格特质及其互动模式的理解，尤其是基于星座特征给出恋爱中的相处建议。 商业模式解读：通过对某些品牌的经营哲学进行剖析，展示了创始人坚守初衷而非盲目追逐短期利益的企业文化理念。 宏观经济形势展望：简述当前中国经济面临的债务重组等问题，并表达了对未来经济发展前景的信心。 生活方式推荐：提出了一些健康生活的实用工具介绍，如使用氧气生成器提高身体状态的方法。 整体来看，本文旨在帮助读者更好地理解和应对生活中遇到的各种情况，无论是在职业道路上寻求进步、管理个人财务还是维护良好的社交网络等方面均给予了积极正面的意见和支持。 以下是文中涉及股票及相关市场的干货内容： 关于科创板：作者认为科创板可能会成为本轮牛市的重要组成部分，并且有望“笑到最后”。 股票技术分析： 对于股票的技术形态，“右侧”被认为是强势整理（即股价上涨过程中回调），而“左侧”的情况则更为不确定。 当KDJ指标出现大幅度调整至负区间时，表明市场上存在大量抛售压力；然而，若持续较长时间处于此状态，则意味着更多的投资者感到担忧并退出。 选股原则： 在A股市场中，尽管个别优质公司的表现可能与其所属板块整体状况不符，但仍需重视宏观经济环境的影响； 建议分散投资组合，其中一部分资金用于购买权益类资产(例如股票或基金)，具体比例可根据自身需求设定。 投资理念： 避免盲目追逐热点题材，注重长期持有具备良好基本面的企业股份； 不推荐参与期货交易，因其具有极高风险并且胜率较低。 其他对投资的看法: 李大霄老师的某些观点虽有一定道理，但他更多是从宏观层面进行分析而非微观细节指导买卖时机； 小米早期专注于单一业务模式取得了成功，类似的战略也可能适用于其他初创型企业的发展路径探索之中。 定势观念提醒： 提醒读者警惕刻板印象带来的误导作用——并非所有声称不盈利的品牌背后隐藏着欺诈行为，反之亦然。 [2024-12-09 03-55-06][zettaranc][为什么你总踏不准节奏？].aac 这篇文本包含了多个话题和对话片段，主要围绕投资理财、情感咨询和个人经历等方面展开讨论。以下是主要内容的概括： 关于理财产品： 讨论了一些具体的投资项目（例如鞋子）及其价格波动。 提到了股市中的操作技巧及风险控制。 房产相关的问题： 分析了几个人在深圳购房的情况，并强调了持有房产的重要性。 对不同城市的房地产市场的前景进行了预测。 星座匹配和感情建议： 给出了针对不同类型情侣组合的情感建议，包括双子男与天蝎女、巨蟹男与摩羯女等搭配方式。 职场与发展： 如何跨部门调动以及人际交往的方法； 有关出国留学的选择意见； 生活方式及其他杂项： 包括购车与否的考虑因素； 职场上的一些心得体会； 理财观念上的指导思想等等。 整体而言，这篇文章通过问答形式探讨了许多实际生活中常见的困惑或难题，涉及范围广泛且具有较强的实用性。 以下是文中提到的一些关于股票和其他投资相关的干货内容： 股票操作技巧： 关于“最小阻力点”的概念：即股价会在阻力较小的地方移动。 利弗莫尔所说的最小阻力点是指趋势发展的路径是最少受到阻碍的位置。 具体案例讨论： 例如，“ZGNB”提问是否可以在次日跟进某个股票（假设前一天未能成功进入）: 如果当天没能追进去，并且隔天确认不是强势上涨，则不要再盲目跟进。 风险管理： 设置合理的止损点非常重要，避免过度追求收益导致重大损失。 长期持有 vs 短期交易： 提到了对于某些投资者来说，频繁买卖不一定带来更好的回报；相反，耐心等待并抓住关键时机更为有效。 房产投资观点： 强调房地产作为一种抗通胀的投资手段的价值，尤其是在一线城市拥有物业的重要性。 在大城市购买房产被视为一种稳健的选择，特别是考虑到未来的租金收入潜力以及潜在的价格升值空间。 理财观念： 建议根据个人财务状况做出合理配置，而非一味追逐热点或潮流商品。 心态建设： 投资过程中保持冷静头脑至关重要，不应受外界噪音影响过多。 其它提及的观点： 对于数字货币的看法较为保守； 针对未来市场的不确定性提出了多种可能性及应对措施。 以上总结涵盖了原文中涉及的主要股市及相关话题的信息要点。","categories":[],"tags":[]},{"title":"24-12-01 z哥直播","slug":"24-12-01-z哥直播","date":"2024-12-02T15:12:42.000Z","updated":"2024-12-02T15:31:04.663Z","comments":true,"path":"f9c61bad5557.html","link":"","permalink":"http://chadqiu.github.io/f9c61bad5557.html","excerpt":"","text":"操作建议根据这位金融博主的直播内容，以下是适合当前的股票操作建议： 不盲目追涨杀跌：博主强调了不追涨杀跌的重要性，特别是在市场没有明确增量资金入场的情况下。他建议大家要谨慎操作，控制仓位。 重视风控：博主多次提到风控的重要性，特别是在操作股票时。他建议投资者在持仓时要设定止损点，以防止大幅度亏损。 关注技术指标：虽然博主提到金叉死叉等指标不是最重要的，但他仍然建议投资者在操作时参考技术指标，例如周线级别的b1和b2信号。 利用市场回调机会：博主提到在市场回调时，可以寻找合适的买入机会，特别是当价格回调到某个关键支撑位时。他建议投资者可以等待市场回调到一定程度后再进行操作。 关注政策动向：博主强调了政策变动对市场的影响，建议投资者关注政策动向，特别是宏观经济政策和行业政策的变化。 耐心持有：对于某些已经持有的股票，博主建议耐心持有，特别是当股票处于上升趋势中时。他提到在市场回调时不要轻易卖出，等待市场反弹后再进行操作。 不盲目跟风：博主多次提到不要盲目跟随市场的热点或短期波动，而是要根据自身的投资策略和风险承受能力进行操作。 利用量化策略：虽然博主提到量化策略需要谨慎使用，但他建议投资者可以适当运用一些量化工具来辅助决策。 重视基本面：博主提到在进行股票操作时，要重视股票的基本面分析，特别是公司的盈利能力、成长性等因素。 综上所述，这些操作建议可以帮助投资者更好地应对当前的市场环境，但请注意，投资有风险，操作需谨慎。 分段内容AI总结[2024-12-01 21-24-08][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 以下是从这段直播内容中提炼出的与股票相关的干货内容： 关于股票市场的短期波动： 直播主解释了股市涨跌是正常的，不必过度担忧。他说：“为什么跌多了就涨涨多了，获利盘多了就杀，这是非常正常的。” 关于“画债”概念的澄清： 直播主多次强调“画债”是一个误区，仅仅是授信额度的扩充，并没有实际发债：“我说啊我其实昨天在直播间就跟大家说了，画债这个概念是很荒谬的，它只是授信额度的扩充，并没有真正发债，所以大家不要把它当成金融市场的决定因素。” 对于空头与多头态度的意见： 直播主表示自己的态度是比较中立的：“我不是多头，我也不是空投，我是华头。” 对于投资市场的长期看法： 他指出现在是赌博式的市场机会：“从散户的角度来看，目前只能算是赌博的运气阶段，但长远看，中国的金融环境仍然相对健康。” 关于通货膨胀的预期： 某些人士提出通货膨胀的观点，但直播主反驳说，真正的通货膨胀需要大规模的货币扩张，目前的实际数据和政策倾向并未支持这一点：“总之，现在发那么多钱都是扯淡，没有任何实践证明能真正刺激通胀。” 对于政策和经济发展的总体看法： 他解释了很多中国人实际从中受益，暗示经济的整体趋势是正向的：“比如基础设施建设、住房改善、医疗教育等多方面的提升，这意味着每个家庭都从国家的发展中获得了实际利益。” 对于资产配置的建议： 强调相比于空转资金，应该利用市场机会进行合理投资：“现在是把握市场机会的好时机，建议稳妥地进行一些投资配置，而不是将大量资金闲置。” 以上主要内容总结了直播主对于当前市场的一些基本看法和投资指导建议，帮助理解他在股票方面的观点和态度。 这段对话内容涵盖了多方面的话题，包括个人经历、直播互动、对时事的看法以及一些具体建议。以下是总结： 个人迟到情况： 虽然是因为路途遥远，且天气良好，作者还是声称没有找到迟到的合理解释，决定不解释。 直播内容： 主要内容围绕正在直播中的微博聊天作业、下周的策略分享会以及对直播策略分析。 鼓励粉丝互动，并减轻新粉丝的压力。 详细介绍了一些之前粉丝的反馈建议，比如基础知识和深度分享。 应对流量和粉丝增长： 对于直播中出现的新粉丝过多问题，暂时保持低调，通过筛选互动，不做过多评论。 采取策略与粉丝互动，比如加大手势表达等方式吸引注意力。 隐含的市场信息和政策： 国内经济现状和政策方向，包括人们对市场预期的变化。 讨论“画债”相关概念，对其提出质疑并澄清谣言。 对中国民众生活和发展方式的观点： 鼓励国人在全球背景下坚守祖国，利用未来发展优势。 阐述通过几十年的发展所积累的基础，不应盲目效仿国外。 一些操作技巧和经验分享： 例如直播间中如何更好地互动以及某些行业销售技巧分享。 个人经历中强调了选择合适的职业发展道路，以及如何通过正确的路径积累资源。 总体来说，内容较为杂乱，涵盖面广，带有些许夸张、搞笑的表达方式。 [2024-12-01 22-24-10][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 以下是从直播内容中提取的与股票相关的关键信息和干货： t加一交易制度： A股的交易制度（T+1）使得短期交易和盯盘的人很难收益。 由于T+1制度，交易日当天买入的股票不能卖出，这为机构投资者创造了套利机会。 散户的盈利机会： 持续关注股价波动中的“买一价”（B一）和“卖一价”（B二）之间的变化。 机构低吸高抛，散户可以通过抓住这些机会盈利。 主力与散户的关系： 机构的实力远超过散户，散户在面对主力时极难稳定获利。 机构会利用散户的追涨杀跌心理，通过高抛低吸赚取差价。 支撑点的重要性： 在关键支撑位（如B一）买入可以为自己创造盈利机会。 长线投资和布局行业龙头公司（如格力、万科）更能获得稳定收益。 价值投资与成长股： 十年或者更长时间维度来看，价值投资是更为可靠的投资策略。 适合价值投资的股票会慢慢增值，最终为投资者带来可观的收益。 避免短线操作： 频繁短线操作或高频交易风险极大，容易亏损。 散户应时刻保持风险意识，避免过度投机。 交易纪律： 投资需遵循自己的交易计划，不要因贪婪追涨或因恐惧而止损。 控制仓位，避免满仓操作。 长期投资与心态： 百分之八十投资者的钱最终会流向少部分能坚持长期投资的人。 散户应该保持良好的心态，而非简单地追逐热点。 希望能帮助到您，节省宝贵的时间。请根据这些信息调整投资策略，若具体股票分析或操作建议仍有疑问，欢迎继续咨询。 这段内容主要围绕股票交易策略和个人投资心态进行讨论。以下是几个关键点的总结： 加压裤和淘宝客服：作者提到一种加压库，价钱在几千到九千多元人民币之间。作者通过与淘宝客服的互动，提出了自己对于勤奋和卷的态度。 股市交易策略：作者批评了简单的技术分析（如金叉和死叉），提出基差（b一）交易是一种相对有效的方法。作者强调了短线交易的风险和收益，并提倡分散投资以控制风险。 投资心态：作者批判了一些人投入大量资金“满仓”操作，认为这种行为风险较高。他分享了自己的投资经验和分仓操作的观点，提醒读者确保投资策略合理且适合自己。 具体技术细节：作者解释了一些包括基差技术、增发等具体操作方法，强调了观望市场的初衷与方向的重要性。 市场经验：作者分享了一些个人经历和市场观察，通过与粉丝的互动，传达了投资过程中保持冷静和灵活的重要性。 总体来看，这段内容包含了对投资策略的深入分析和个人心态的引导，作者试图通过分享自己的经历和见解，帮助读者更好地理解市场和制定自己的投资计划。 [2024-12-01 23-24-10][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 从你的描述中提取出的股票相关干货内容如下： 关于美国移民政策： 美国吸引全球人才，同时收纳底层劳动力，但不总是按照速度来，有时快有时慢。 中国边境封闭，没有大规模非法移民问题，中国不需要这样的移民。 关于股市判断： 股市涨跌不重要，最终比的是公司的业绩和成长性。 跟随市场情绪，但最终还是需要理性分析。 关于比亚迪等股票操作： 大型股票控股股东对盘面影响巨大，但对散户来说，只能是棋子。 股票操作需要看空盘关键时刻，看大势操作，而不是紧随主力脸色。 关于股票买入时机： 周线图是一个重要交易辨识工具。 在周线大幅下跌之后找第一买点，如果指标开始钝化，持续买入，直到第一仓。 具体买点包括周线的拐点，需要根据股票核心节点和情绪反射操作。 具体操作策略： 初次翻倍之后回调，往往是一个抄底机会。 确认大底后，开始逐步增加仓位，等待机会。 站在不同角度，看看拐点是否能形成判定买入点的标志性指标。 案例分析： 以比亚迪为例，分享了具体的操作逻辑，从底部翻倍再到回调，如何进行阶段性成本结构调整。 不盲目追涨，注重止盈止损管理，避免金字塔加仓带来的风险。 交易纪律与心态： 遵守交易纪律，不从众，不沉迷于止损，尤其是不要在技术指标完美时甘于错过。 持之以恒的交易纪律，避免盲目行为，保持理性判断。 这段内容的核心观点是对某个股票（例如比亚迪）的操盘策略以及相关分析，包括股票的绩效、买卖点、市场趋势理解等方面。作者通过分析周线图表和历史数据，提出了以下几个关键观点： 拉长持仓周期：作者认为，成功的股票投资需要耐心持有一个较长的周期，这样才能实现良好的回报。 分析关键买卖点：通过具体分析股票价格走势中的关键点（如周线突破、回调谷底、最新的执行力等），作者为投资者提供了具体的买点和卖点建议。 避免盲从市场情绪：强调不盲目跟从市场情绪和暂时的市场表现，而是在理解整体市场趋势和股票基本面的基础上做出决策。 处理复杂市场情况：通过实例分析复杂的市场环境（如特殊政策、市场情绪波动等），说明在复杂的市场环境中如何保持理性投资策略。 持续关注和调整：强调持续观察市场动态和股票表现，针对性地进行投资策略调整。 总体而言，作者通过对具体股票投资案例的分析，强调了长期持有、关注稳定的市场趋势和关键技术点、避免情绪化操作、灵活调整策略等方面的重要性。 [2024-12-02 00-24-10][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 以下是直播内容中提取的与股票相关的干货内容： 股票整理形态： 在周线级别的三角形整理形态结束之后，预计会形成突破。 整理形态结束后，可能会直接向上突破并到达550点左右。 仓位管理： 由于外部因素（如美国汇率打压、贸易战、房地产问题等），降低了市场情绪。 个人仓位已经从80%增加到90%，并保持高度警惕。 买卖策略： 当左侧转右侧时，在日线级别的大幅度负值处加仓。 日线拐点或大利空出现时，寻找加仓机会。 如果右侧已经确认，则不要追高，应寻找日线的大幅度负值点进行加仓。 注意观察周线的大幅度值作为加仓依据。 风险控制： 每个区域都要保持警惕，一旦跌破成本区域，不应再进行加仓。 需要仔细分析价格区间和价差，避免盲目追高。 案例分析： 分析了B一形态以及加仓点的选择，强调了左侧转右侧的加仓时机。 举例说明了10月之后的操作策略，强调了不要追高，而是利用价差进行操作。 心态和信念： 强调在做任何事情时都需要坚持信念。 提醒投资者保持耐心和信念，才能在长期投资中获得成功。 这些内容涵盖了股票操作中的重要策略和技巧，可以帮助投资者更好地把握市场机会和风险。 总结如下： 作者在分析市场走势时，认为当前市场即将突破上升至550附近，但需注意外部因素如汇率变动、贸易战等对市场的影响。当前市场已经脱离底部区域，作者根据左侧转右侧的原则，在成本区间210到230之间进行操作。市场未来可能会有回调，但作者认为这是入场加仓的机会。 整体操作策略包括： 跟踪市场趋势从下跌转为上升。 在成本区间进行操作，确保仓位控制。 从左侧转为右侧操作后寻找加仓机会，特别是在日线图上找到大负值的时机。 等待周线大幅值回到成本区域时再加仓。 注意价格区间和价差，而非频繁操作。 上述策略强调了技术水平分析、仓位管理和耐心等待的机会的重要性。同时，作者也警告了外部不确定因素可能带来的市场波动。 [2024-12-02 00-59-08][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 依据您的要求，提取的股票相关干货内容如下： 关于B1和B2的操作策略 B1：当出现B1时，不要轻易追涨，保持观望态度，等B2明确赚钱信号后再加大仓位。 B2：如果出现B2的放量阳线突破，就可以跟随买进，首选信息披露较大的票，因为基本面更透明。 市场当前趋势与操作策略 目前市场整体仍在交换筹码，短期内不要盲目追涨杀跌，可以通过监控大盘指数，捕捉合适的入市和出场时机。 机构操作与预期 预期市场可能会出现新的散户资金入场，留意公募基金的动向，尤其是周五的交易日晚，可能有新的大资金入场进行建仓。 市场操作风险与收益关系 预期未来市场的波动会减小，提醒投资者在不同阶段要明确自己适合的操作频率和幅度，不要过度操作。 趋势识别与技巧 教导观众通过三角形整理形态、反转向上的突破等技术手段识别交易机会；同时说明频繁的T战术（日内交易）并不适合所有人，要求参与者根据自己的盈利风险偏好来选择适宜的操作模式。 具体的实践操作 详细解释了“喝酒”（MACD）、八线成本等技术指标的应用方法，强调寻找短期支撑和阻力位来引导操作。 以上内容为直播中提到的股票相关的投资建议及技术分析。 这段内容是直播间的总结和鼓励，主播分享了一些关键交易策略和经验，并回答了观众的问题。主要内容可以总结为： 交易策略与原则： 分析市场趋势和增量资金入场情况。 强调交易纪律，不盲目追涨杀跌。 利用“B一”、“B二”等技术形态指导操作。 心态与操作： 建议投资者保持稳定的心态，关注风险控制。 信任自己的操作策略，避免急躁。 市场动态与机会： 讨论了市场调整和整理区间的看法。 强调短期波动不可预计，建议投资者根据实际情况灵活操作。 直播间互动： 与观众互动，回答了关于交易策略的具体问题。 在互动中分享了一些特定交易对象的操作心得和体会。 后续操作建议： 适时观察市场表现，适时采取行动，不要盲目跟进。 提醒投资者注意盈亏平衡和风险控制。 特殊提示： 针对一些特定的交易对象和操作手法进行说明，确保避免被误导或失去控制。 在总结中，主播强调了投资者需要具备纪律性，并根据市场情况进行适当的调整和操作，以达到良好的交易效果。 [2024-12-02 02-13-41][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 提取出的与股票相关的干货内容如下： 股票市场现象： 大盘与板块轮动：股票市场会经历板块轮动，而不是所有股票同步上涨。机构资金会在不同行业轮换，造成市场波动。 下跌与上涨：机构和国外投资者有时会推动某些板块下跌或上涨。例如， Rodríz 似乎成为了关注的焦点，甚至可能引发中煤能源的大跌停。胆固醇能源等煤炭公司的短期下跌是机构筹谋的一种方式，以实现其策略目标。 投资策略： 股票投资需要灵活应对市场变化，“打基础，求战略”是进行量化交易的关键，不能过度依赖单一策略，应该根据市场环境调整投资组合。 长期而言，投资策略需要经过一段时间才能显现效果。分段投资是稳妥的选择。 投资建议： 谨慎处理投资组合扩展：如扩大股票投资从单一的低风险策略放宽至高风险策略，需要有风险意识和适当的分散投资。 关于资产配置，建议在配置牛策略于长期基金中时，总有一些短期调整值，比如R1或R3信用债券，个人实际情况和风险偏好不同。 总结：本期内容主要围绕股票市场动态、板块轮动、投资策略和风险控制进行讨论。强调把握市场趋势，根据市场变化灵活调整投资组合，保持投资纪律的重要性和具体操作建议。 这段内容是一段用户与直播间的互动记录，内容复杂且包含许多个人问题和情感表达。概括主要要点如下： 互动活跃：用户们在直播间积极互动，很多用户都提出了问题，包括个人情况、星座匹配、投资策略等方面的咨询。 情感表达：其中充满了用户们的情感表达和对一些特定用户的关注，例如“小龙虾”、“对角巷小龙虾”等昵称。 投资建议：针对一些用户的投资问题提供了专业建议，包括股市投资策略、风险管理等方面的指导。 个人情况：用户提出了各种个人情况咨询，如感情问题、工作压力等，主播也针对这些情况给出了建议。 博彩反馈：主播强调不希望用户滥发消息，尤其是涉及转账、购物等方面的讨论，以确保直播间的纯净。 感情建议：对于感情咨询，主播给出了不少具体的建议，帮助用户更好地处理外界压力和情感问题。 这段内容反映了主播与直播间用户之间紧密互动的关系，为用户提供多样化的帮助和支持。 [2024-12-02 03-13-56][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 以下是从直播内容中提取出的股票相关内容： 关于股票交易和策略： 短期内频繁出现平价大宗交易非常正常，不用过多关注。 白洋淀政策：当前并未完全放开，需要等待政府给予更有力的政策支持。 做期货时，应关注基本面和经济周期，以便做出正确的决策。 股票最小阻力位和情绪价值：涉及到股票技术分析的具体方法较为复杂，通常需要较长时间来解释清楚。 提醒：不要在没有政策支持的情况下，单纯依靠市场机制发展。 具体操作和策略： 做大宗商品期货时，应关注基本面变化，而不是纯粹的技术分析。 做商品期货时，对于基本面的判断是至关重要的。 有的时候可以通过卖出平价商品的方式来测试市场的反应。 考虑到目前市场环境和国际形势，期货交易较为困难，不适合新手参与。 例如对于储能行业的发展预期，储能爆发或将与光伏行业的发展紧密相关。 市场形势： 央行货币政策和国际形势对市场的影响，例如美国政策变动不确定性，影响了大宗商品价格的变化。 大部分市场参与者仍在等待更多的政策信号和支持信号。 警惕市场的一些负面信号，如主力可能在试探市场。 个人建议： 坚定看多优质资产，支持中国互联网公司的长期发展，看好腾讯作为中国最大的互联网公司。 重大决策需要长时间的观察和验证，不要轻信短暂的市场变化。 以上总结了直播中提到的关于股票交易和市场分析的相关内容，希望能对你有所帮助。 内容主要是关于星座、职场建议、投资置业、情侣相处策略等方面的讨论和咨询。具体总结如下： 职场建议： 欣读交流：约定了周转工作的注意事项。 Qwen给出了关于从小公司转到大公司工作的建议。 对应基数发展：提供了巨蟹男、巨蟹女对婚姻的看法和建议。 投资置业： 建议经济活动：对北京楼市和白洋淀政策给予了几次有意义的分析。 强调实体店和传统房型究竟何时购买合适。 星座咨询： 关于恋爱和婚姻：探讨了各类星座的配对建议和情感管理策略。 针对单身群体提供了择偶建议，如巨蟹女、巨蟹男的追与被追。 个人成长建议： 巨蟹男与其他星座男的关系指导，例如如何处理天蝎女、处女女等特定星座女的问题。 小型企业升迁的职业规划思路。 特定问题： 投资建议：如科创板股票和上证指数的入选标准。 个人爱好和技能发展：鼓励探索个人爱好及兴趣点。 总结而言，这些交流涵盖了财务规划、工作发展、人际关系以及自我成长等多方面的生活议题。 [2024-12-02 04-13-56][zettaranc][看懂一张图，一生不缺钱～12.1晚九点开].aac 从这段金融主播的直播内容中，提取出的股票与投资相关干货内容如下： 港股投资选择：直接推荐使用港股通，而非直接在香港交易所开户，原因是港股通标的相对较为安全，不会被外部忽悠。 止损策略：在期货市场交易中，设定止损位是很关键的策略。遵循的原则是，只在一次趋势性反转的K线中止损一次。 股市策略：对于大学生或者初入市场的投资者，建议首先阅读相关书籍，如“十年一梦，成名之境”等。了解期货市场的基本原则和技术分析后再进行操作。在确定的投资布局中，持有仓位应尽量控制在半仓以内。具体的仓位控制还需要根据市场情况进行灵活调整，不必急于快速盈利。 市场趋势分析：目前市场处于逐渐收敛之中，没有大机会出现。投资者应当耐心等待市场出现明确的方向变化。在政策层面，建议关注政策导向，避免盲目乐观或悲观，因为类似重要的经济会议期间市场通常会呈现下跌的趋势。 这段内容是一个直播对话汇总，涉及多个话题，包括个人经历、投资建议、星座解读等。总结如下： 个人经历与感情：主播分享了关于感情的观点，表达了珍惜当下的态度，并提到了一些幽默的例子，如处女男和射手女的相处模式。 投资建议：主要是关于港股投资的建议，认为港股通相对更加稳妥，同时也分享了关于期货交易的一些止损和策略分析。强调稳重和风险控制的重要性。 星座解读：包括天秤座儿子的性格特点、巨蟹座的专属歌推荐、以及一些个人与星座之间的互动等。 直播间互动与问答：主播回答了观众关于情感、工作、投资等方面的问题，并提供了一些建议。同时，主播也分享了一些关于市场和个人发展规划的看法。 结束语：直播最后主播表示了对观众的支持和感谢，并鼓励大家乐观面对生活。 整体来看，这段内容展现了主播与观众之间的互动和分享，涵盖了生活、情感和投资等多个方面的话题。","categories":[],"tags":[]},{"title":"24-11-24Z哥直播","slug":"24-11-24Z哥直播","date":"2024-11-26T16:50:26.000Z","updated":"2024-11-26T16:52:38.654Z","comments":true,"path":"a42e1736d2ee.html","link":"","permalink":"http://chadqiu.github.io/a42e1736d2ee.html","excerpt":"","text":"[2024-11-24 20-01-03][zettaranc][如何备战第二阶段（11.24晚8开）].aac 根据提供的内容，以下是从直播中提取的与股票相关的干货内容： 关于“赤猴”的概念： 赤猴指的是探子：主要用于试仓、探测市场信息（如第一次探路）。如果探子带回了重要信息，就可以大胆跟进；如果被逮住，可以视为试错的一部分。 赤猴的概念误区：一些人认为连续的损失就是全部“赤猴”的失败，但实际上可能只是其中一小部分“赤候”失联，并不代表全部的损失。 关于市场情绪和策略： 市场总是要洗一次盘：主播认为必须引导市场进入调整阶段，形成一定程度的信心，这样才能方便机构换手布局。 调整是为了筹码换手：市场必须经历调整，之后主力会重新布局筹码。打击市场中的恐慌情绪，让投资者在这种“调整”的形态中逐步加入，最终形成新的走势。 关于股票操作技巧： 不要盲目追涨杀跌：主播强调不要受到市场情绪的影响，有时避开市场追涨杀跌，等待更好的底部再介入可能会有效。 试仓方法：以小仓位开始，如果在试仓过程中发现行情不符合预期，应迅速止损。 克服心态障碍：保持心态平和，及时止损，不要臆断市场唯一正确的方向，要学会分析和接受市场变化。 关于具体股票操作案例： 新前锋的仓位管理：主播示例说小范围持股，如果有操作机会则及时调整仓位，保持警惕以应对市场变化。 量能和价格关系：股价的量价关系是判断买卖时机的重要指标。如果发现某只股票量价共振，低点区域或有大幅值，可以为左侧操作提供依据。 明确心态： 监盘和操作时，应该保持一颗平常心，关注量能变化和市场情绪，而非一时的涨跌。 关于个人情感生活建议： 射手男追水瓶女的攻略：情感和股票都一样，需要理解对方的个性，投其所好，保持耐心，投资也应如此。 整体情绪掌控：保持乐观的心态，对待感情和炒股一样，不应过于悲观或急躁，恰当的乐观有助于做出正确的决定。 这些内容强调了对市场和技术面的重视，同时也建议了理性投资的心态。希望对你有所帮助。 这段内容是直播中的一段总结与讨论，主播回顾了近期的直播内容，并解答了观众的问题。直播内容涉及以下几个主要方面： 设备与直播问题：主播提到小米系统升级到2.0后，b站直播机没有更新，导致直播机横屏时经常闪退。主播打算下周解决这个问题，并考虑使用苹果设备作为替代方案。 对“赤猴”的定义：主播解释“赤猴”是历史上的探子或侦察兵，并澄清了相关误解。 收看方式及操作细节：主播建议大家根据屏幕方向选择合适的观看模式，并解释了一些操作细节，如弹幕使用和手势切换。 股票市场分析：主播讨论了近期股票市场的波动情况，包括“赤猴”策略应用、期货市藁仓位管理等专业术语。 个人事件与互动：主播还提到了与粉丝互动的个人事件，包括接收到的礼物、收到的朋友请求、以及粉丝的留言和建议。 心态与原则：主播强调心态的重要性，认为“试仓”是关键，以及市场必须通过多空博弈、投机与止损来实现合理的调整。 具体操作与建议：主播给出了关于股票持仓和处理策略的具体建议，包括如何判断市场趋势、何时止损等。 总结来说，这段内容涵盖了直播中的技术配置、市场分析、粉丝互动和个人感悟等多个方面，体现了主播作为财务博主的专业性和个人风格。 [2024-11-24 21-01-14][zettaranc][如何备战第二阶段（11.24晚8开）].aac 根据您提供的金融主播的内容，提取了以下与股票相关的干货内容： 运营策略： 选择自己看懂的票，拿得不动。 市场观点： 选择看涨的市场状态下持有的股票（如整体月线走势向上）可以获得较好的收益。 大盘转向时表现不佳，因此操作方面看到市场发生变化需及时调整状态。 投资建议： 换和其他人多交流，提供给朋友提供少量的价值，希望大家少亏钱甚至不亏钱。 提前交代的操作策略是拿着一个“太子”进行长期持有，即认为可以穿越整个牛市。 风险提示： 当市场风格变化时波动大，不必过于恐慌，但应引起重视。 不进行频繁操作：强调了即便再操作，也应看清楚市场走势，只有大盘向上才不亏。 解释原因： 选择的股票要看懂基本面，分析他们历史走势和量化模型进行配比。 实例说明： 一些朋友（如峰哥）因为持有稳健医疗而被套牢。 强调即使有较好的操作，但如果市场趋势下行，投资将受到大的影响。 提供具体投资行为建议（如在屏幕上划动进行操作）以防操作失误。 总结了一段主播的核心经验和教训：坚持长期持有自己熟悉的股票，不频繁操作，并分析市场趋势，避免因市场波动过大出现较大风险。 这段内容是一位直播主在阐述关于投资市场和个人投资策略的看法。总结如下： 市场波动：主播提到市场表现不稳定，自己也在考虑切换到苹果股价作为投资标的。但更关心的是分享自己的投资理念。 投资策略：主播重视长期投资，强调选择自己能理解并看得到的股票，保持满仓操作，减少频繁操作带来的风险。 市场风格的变化：主播表示会面对市场风格的变化，市场下跌时可以认命，但上涨时则期待市场持续上升走势。 操作建议：主播建议投资者在市场看涨时继续持有，但下跌时减少操作，避免追高被套。同时也提醒频繁操作可能带来风险。 预防措施：主播强调要树立正确的投资观念，避免频繁操作，通过选择易于理解的股票或处于相对安全的“潜水区”来减少风险。 个性与强制执行：主播提到一些投资者虽然知道应该操作少一些，但他们依然会频繁操作，这种行为带来的问题在于可能会失去耐心和理性。 沟通反馈：主播吐槽一些投资者不听从建议，比如继续高位买入造成亏损。他建议投资者认真考虑是否适合进行市场操作，而非频繁行动或盲目追高。 互动方面：直播过程中，主播与观众进行了一些互动，并有所抱怨观众的操作习惯。 总体来看，主播试图用通俗的语言和实际例子来分享自己的投资观点和策略，同时也强调自己的投资理念和观众的操作习惯之间的矛盾。 [2024-11-24 21-18-12][zettaranc][如何备战第二阶段（11.24晚8开）].aac 从这段直播内容来看，提取到的股票相关的信息较少，主要是主播的一些技术操作问题和画面调试的讨论。但是，如果要提取与股票或投资决策有关的内容，可以关注主播在谈话中提到的投资决策建议或者市场分析。以下是从该段内容中提取的与投资决策相关的信息较为有限的几点： 技术操作调整：主播提到尝试了更换不同的手机品牌（小米和华为），并考虑使用电台模式来改善直播画面。但并未直接提及具体的投资决策建议。 市场情感因素：主播多次提到对设备画面的观感偏差，似乎表明对市场或投资环境的看法受到情感因素的影响，但这种主观感受并未转化为具体的投资决策建议。 市场热门话题：主播提到了一些热门的股票代码或者投资方向（如game sty k西北k cc北三七），可能间接涉及投资决策，但并未具体说明这些股票或投资方向的优劣。 从这段直播内容中，暂未发现直接针对具体某只股票的投资建议。如果需要获取更精确的投资建议，建议关注专业投资分析或使用专业的股票研究工具。 这段内容描述了一位用户在观看直播时遇到的画面问题及其调整尝试过程。用户觉得画面特别红、刺眼，而且之前的直播画面大且近。为了调整这些设置，尝试了以下几项操作： 重启手机（小米），以改善画质。 考虑调整为电台模式。 换用华为设备进行直播。 进行磨皮设置的恢复以改善画面质量。 但即便如此，用户仍然对画面效果不满，尤其是红色调的问题持续存在，导致整个五官模糊。最终，用户表示该直播效果难以接受，表现出一种困扰和不满意的语气。 [2024-11-24 21-26-35][zettaranc][如何备战第二阶段（11.24晚8开）].aac 从您提供的直播内容中，提取出的与股票和股票相关的信息如下： 股票操作建议：主播建议“别操作了啊，就拿住不动就完了”，并提到因为频繁操作导致损失了二十分钟。 话筒插个电会卡：主播提到“我怕它卡。对，就这样了不不，咱们不再折腾了啊”，这句话可能涉及某个通讯设备或软件在接电后容易出现卡顿的情况。 股票推荐：主播推荐“还得是小米儿，真的还得是小米华为”，表明在他的直播间，小米和华为股票是被推荐的股票。 虽然直播内容中提到了一些与华为相关的评论，但没有明确指出是股票投资的具体建议。从主播的表述来看，更多是在推广自己认为好的品牌，而非具体股票买卖建议。 希望上述信息能够帮助您节省时间并获取所需信息。如果您有其他具体需求，请随时告知。 总结如下： 对话内容主要围绕以下几个方面展开： 停止操作：对话开头提到不再进行任何操作，已经浪费了二十分钟。 讨论手机：提到小米和华为，表示无线设备的充电和操作问题。 电池电量担忧：目前电量只有一小部分（百分之二十八），担心使用华为设备充电时可能会导致过热和卡顿问题。 情感表达：表示非常喜欢某些产品和技术，尤其是来自中国的品牌（例如小米和华为），表达了对中国品牌的支持和热爱。 澄清立场：强调自己并没有对华为有任何不满，只是担心电量问题。 未完成的事情：提到准备开始做一些事情，但又担心迟到问题。 整体来看，这段对话中含有一些矛盾和不确定的表达，可能是因为对话中的某些情绪波动所致。 [2024-11-24 21-32-03][zettaranc][如何备战第二阶段（11.24晚8开）].aac 根据提供的内容，以下是提取出的与股票相关的关键干货信息： 净值曲线与心态： 如果你能保持净值曲线平稳，且在市场波动时选择拿住不动，你很可能具备一些投资天赋。 保持心态平和是长期投资的重要原则。如果你在市场波动时无法冷静对待，可能会亏钱。 风险管理： 对于亏损30%以上的投资者，建议止损，不要继续持有。这些投资已经亏损过多，进一步操作可能带来更多损失。 对于亏损10%到20%左右的投资者，虽然市场波动较大，但也不需要过度交易，继续观望一段时间可能更为明智。 对于未亏未赚的投资者，保持不变的操作策略，观察市场波动，以确保账户盈利。 市场预测与交易策略： 市场无法精确预测，但当你已经买入股票时，如果市场没有证明你是对的，那么你就是错的。 追涨杀跌在任何市场阶段都不是有益的策略，保持冷静，不追加亏损的投资。 交易纪律： 不要预期未来市场的走势，应更加关注账户变化，确保不会让盈亏反转。 确保盈亏控制在合理范围内，及时退出不符合预期的操作。 如果能够在未来两天内全身而退，保持账户盈利，这就是正确的交易策略。 心态调整： 增强对市场波动的心理承受能力。 不要因担心出现尚未预料的市场情况而犹豫不决或做出错误决策。 具体操作建议： 目前市场上有普遍浮盈的股票保持不动即可。 对于有浮亏的投资者，应设定止损点，提前退出避免进一步亏损。 不要去天真的寻找极端波动下对利润的贪婪，避免大失误。 这些干货信息强调了心态、风险控制和交易纪律的重要性，特别是对市场的理性预测分析。 这段内容是一段直播节目的总结，主播在直播中讨论了财务和投资的主题，并分享了一些关于市场的见解和建议。以下是主要内容的总结： 直播氛围与互动： 主播提到今天的直播是第三场。 他随机点名一些观众送出霸王茶几等奖品，包括来自不同城市的参与者。 主播对一些观众的操作给予具体指导，并对一些由于操作不当而获利受损的观众进行了劝诫。 市场看法与策略： 主播认为每个人都有自己的投资策略和适合的投资组合。 他强调对于浮盈的人来说，应该保持冷静，不要急于追涨杀跌，否则可能造成亏损。 主播提醒投资者要小心那些承诺有较高收益的投资机会，因为这可能是不切实际的幻想。 他建议投资者首先要确保自己的账户在交易中不亏损，然后在市场反弹时再考虑操作策略。 对于当前浮盈或者账面亏损的投资者，主播分别给出了不同的建议，既有保留不动的建议也有建议止损离场的建议。 直播参与与互动： 主播经常通过公众发言来引导观众发言，提升观众的参与度。 他还收到了一些观众的处境反馈和详细操作建议，主播给予了反馈和支持。 整个直播中也穿插了一些对评论区弹幕互动和具体观众行为的调侃和解释。 主题延伸： 在直播过程中，主播还提到了一些市场操作的概念，如净值曲线、止损点、浮盈与浮亏的控制等。 他提到了一些市场观点，如有些人可能会因为市场的大波动而被套牢，或者在市场回调时需小心操作风险。 总结而言，这段直播充满了互动和实际操作的建议，主播不仅分享了自己的经验，还给予观众具体的指导和鼓励。 [2024-11-24 22-32-16][zettaranc][如何备战第二阶段（11.24晚8开）].aac 下面是从提供的金融主播直播内容中提取的股票相关干货内容： 停止加杠杆炒股 主播多次强调不要使用杠杆炒股，不要借钱或利用融资融券炒股。(多次提及) 适时止盈 主播指出，对于浮动盈利较大的投资者，不应等到满仓后再卖出，而应当适时止盈以避免市场突然下跌带来的损失。(多次提及) 交易纪律的重要性 主播强调，对所有投资者最重要的是遵守交易纪律，尤其是对于浮动盈保持较合理仓位进行操作。(多次提及) 市场资金进退策略 主播描述了市场的资金流动规律，指出在市场上涨阶段新的入场资金是市场的一部分，而在市场见顶后，新的资金应逐步出货。(提到四个市场阶段) 低波红利策略 介绍了一种低波红利策略，这种策略是通过选择稳定表现的股票，实现长期稳定获利。(多次提及) 止损规则 提供了具体的止损规则，例如设立基于K线止损的具体位置和操作步骤。(多次提及) 市场不确定性与风险管理 强调要在了解市场不确定性的情况下，正确评估仓位风险，及时进行风险控制，避免本金大量损失。(多次提及) 个人投资建议 建议投资者们在不确定时避免过于激进的操作，比如不要对市场行情产生过多情感依赖。 综上所述，注重保持股票投资的纪律性、掌握时机进行止盈，并建立正确的风险控制意识是关键。 这段内容是一段直播记录或访谈记录，主要讨论了以下几个方面： 市场波动与个人损失：记录中提及有人在市场波动中追随情绪进行交易，并选择性上杠杆做高风险操作，最终损失惨重。直播者认为这种行为是不理智且有害的，并表达了对此事的愤怒和失望。 理性交易的重要性：直播者反复强调多次的教训，坚持不要上杠杆、不要借贷炒股的重要性，认为理性的交易纪律能够帮助人们避免不必要的损失，尤其是在市场波动时。 市场周期与操作策略：直播者分析了当前市场阶段的特点，以及第二阶段的可能时机。预测市场会经历起伏，且各部门的不同表现将影响整体走势，呼吁观众在市场不同阶段执行不同的操作策略。 个人经历与案例分享：记录中提及虽然有成功的案例，但部分人因抄底错时、追高失误等原因导致较大损失，讨论如何通过技术手段选择低风险高收益的产品或策略，如低波红利、保命策略等。 情感与观点表达：直播者认为与其抱怨市场不可控，不如理解和实用地运用交易策略，但同时也不必太过于苛责自己。表达了希望观众能够理性对待市场波动，依据具体情况进行操作。 总结起来，这段内容主要围绕市场运作及其个人交易实践展开，强调理性交易、风险控制和个人能力提升的重要性。 [2024-11-24 23-32-16][zettaranc][如何备战第二阶段（11.24晚8开）].aac 从你的金融主播直播内容中，提取出的股票相关干货内容如下： 找低位点操作：“您是创出新高以后往下杀第一波了，你把往下杀到那第一波那个低点，记住那个地点了吗？起来您可能是在这儿追的对吧？没关系，现在是不是回到这儿了，一个地点，您给连个线，连个线啊损也好，还是什么无辜了。” 投资心理提示：“赚的就是你的钱赚的就是。” 长期投资观点：“因为我每次都认为其实你要还长，还长城题材贼多呢，还还还抱有幻想。” 不回答某些问题：“哥们儿，就是你们玩幺五玩游玩游资票的被套了的，我一律不回答，你们也不要发弹幕了。” 三不原则+四不原则：“咱们无论老朋友啊还是什么，把三不原则再打出来，再加上四步，对不对？后来又加了一步，把四不原则打出来等着你。有人说说摸腰骨反弹口，这是咱家的四部原则。” 这段内容主要是一位投资者分享关于股票交易的心得和建议。具体总结如下： 投资者提问：投资者遇到问题，寻求解决方法。 市场分析：讨论了不同的市场阶段和相应的操作策略。 情绪与策略：强调投资者在市场波动中的情绪管理，建议不要激动，保持冷静。 市场提醒：提醒投资者近期需要遵循三不原则加上新的四不原则，并分享了自己的投资策略，即所谓的“四步原则”。 积极态度：鼓励投资者记住这一经验，并保持冷静应对市场变化。 从整体来看，这段话主要集中在股票交易过程中的心理调适和应对策略，旨在帮助投资者更好地把握市场动态和情绪管理。 [2024-11-24 23-38-19][zettaranc][如何备战第二阶段（11.24晚8开）].aac 以下是直播中关于股票的干货内容总结： 国足概念评价： 国足不是妖股，稳定如中国远洋、中国石油，每场比赛都能带来稳定的收益率。 总结个人对国足的支持态度，强调国足是国家自己的球队，应支持。 股票仓位管理与调整： 现阶段仓位管理的重要性，包括何时买入、何时调整仓位。 股票下跌的特定条件下可调整仓位：如果股价回撤幅度不超过10%，则继续持有。 止损策略： 提醒新手投资者要止损，控制风险，不要盲目追涨。 领涨股分析： 提到目前市场缺乏明显的领涨股，“龙头”至今未出现，因此需要耐心等待。 市场发展趋势： 提示第二阶段的备战步骤，包括持仓整理、等待增量资金入场、调整仓位。 具体操作建议： 适时调整仓位，利用诱空或诱多的k线图形进行交易。 保持小仓位，如10%-30%的仓位动态调整。 风险管理： 重新调整仓位时，注意个股的基本面和宏观经济环境的变化。 长期稳定与短期波动之间的平衡，如保持持仓不动以保护前期盈利。 老朋友与新手仓位管理建议： 对于有明显被套且未结账的投资者，建议调整仓位或采用小仓位试探性操作。 历史与经验教训： 过去十几年对股市投资的历史总结，强调市场波动中的风险管理。 强调耐心等待和长期投资策略的重要性。 心态与专业心态： 建议投资者保持专业且冷静的心态，避免情绪化操作。 总结： 当前市场缺乏明显趋势，需要耐心等待并调整仓位。 注意控制仓位，操作上应基于对个股基本面及宏观经济环境的分析。 买卖操作需结合市场大势进行，坚持长期投资策略，避免频繁操作带来的风险。 这段内容涉及股票交易和个人投资建议，概括如下： 个人投资态度：作者强调了对国足的支持，但主张以冷静、客观的态度看待投资国足股票（疑似谐音梗）的态度。同时，作者表达了对自身持仓股票的信心和对市场未来趋势的判断。 市场分析与操作建议：作者提供了几个步骤来备战第二阶段的市场变化： 处理当前仓位：清理无用仓位，保持仓位清晰。 等待增量资金：等待市场出现新的增量资金。 及时调整仓位：在找到合适的时机重新调整仓位。 止损与调整仓位：作者强调必须根据实际市场表现和标的特性及时止损，而不是盲目持有；同时应当适量关注新机会。 心态管理：作者认为心态对于投资决策非常重要，分享一些交易心理练习的方法，比如记录每次交易错误、减少冲动操作等。 实例说明：用具体实例说明一些投资策略，比如仓位管理、止损策略、市场预期等。 市场前景讨论：讨论了中国股市与其他国家市场的估值对比，认为中国股市的整体估值相对较低，并提出了对近期股市走势的一些看法。 综上所述,这段文字充满了投资策略和观点分享,作者希望听众能够冷静、理性地面对市场,并根据自身情况灵活调整投资策略。 [2024-11-25 00-38-31][zettaranc][如何备战第二阶段（11.24晚8开）].aac 根据您的需求，以下是提取出的关于股票投资和操作的干货内容： 投资心态和经验分享： 保持耐心，不要急功近利。并非所有的股票波段都会有第二个波段，很多“妖股”都是在一个阶段的行情之后才能显现。 从长期来看，股票市场七成都是男性的投资者这一说法并不准确，更多是个人习惯和兴趣导致。 炒股技巧： 提议采用“亚马尔”策略进行操作。在关键位置及时跟进买入，并在适当的时候减仓到三分之二仓位，以减小风险。 了解透明的市场走势是基于模型计算，需要不断回测和调整策略。 不建议频繁操作。类似有经验的投资者会在判断后一次性加仓或者平仓，不轻易跟随热门股。 市场观察和操作贴士： 市场有增量资金，前期获利盘的洗出会产生一定波动。把握好这种机会，而不是试图提前抢跑。 如果前期操作策略失误，下次操作应该遵循纪律，即使结果是错的，也是正确的操作。 利用技术分析工具，如MACD等，可以辅助判断投资时机。具体操作时需要注意技术指标的选择和运用。 心理与风险控制： 批评了单纯追求高涨幅的心态，强调应保持风险意识，不进行纯粹博弈。 经验教训强调了止损的重要性，具体操作中多次提到不追高，控制仓位的操作策略。 对于新手投资者来说，先从小额模拟盘入手，了解资金流动和资产操作的基本逻辑更为重要。 个人投资风格与抉择： 选择股票并非只需要靠消息和市场共识，更重要的是个人的研究和判断。 投资过程中，要学会平衡操作中的贪婪与恐惧心态，找到适合自己的安全垫区间。 这些建议帮助理解了主播围绕股票市场的一些基本策略和实际操作，希望对您有所帮助。 总结： 该直播内容主要围绕股票投资策略、个人经历及粉丝互动展开，强调了市场中的机遇与个人抉择的重要性。主要内容包括： 投资策略：强调“亚马尔策略”，即在股票的初始上涨阶段低买高卖，实现收益最大化。同时，分享了如何通过模拟盘和实盘的区别来更好地理解投资。 市场洞察：提到市场中脉络的重要性，以及新手投资者可能错过的机会，强调实战经验的重要性。 市场环境分析：分析了市场当前的状态，提到外围资金对市场的影响，并指出外资入场带来的积极效应。 粉丝互动：直播中多次提及粉丝的问候与反馈，表达了对粉丝的支持与理解，同时也分享了一些投资建议。 个人认知与性格影响：提到不同星座在投资决策中的影响，强调个性特征对于投资策略选择的影响。 整体而言，该直播内容充满了个人见解和实战经验分享，旨在帮助投资者更好地理解和应对市场的变化。 [2024-11-25 01-38-31][zettaranc][如何备战第二阶段（11.24晚8开）].aac 以下是提取出的与股票相关的干货内容： 股票投资: 基金经理趋势分析: 价格最大的反弹是在底部月线突然释放出巨量，说明上涨动力很大。 组合投资的多样化: 当某一只股票表现优秀，导致整个组合波动过大时，应考虑减仓以保持组合的稳定。 应该保持个股仓位在总体投资组合中的上限比例，避免单一股票占比过高影响整体波动。 交易策略: 仓位管理: 一旦收益到你认为安全或不能接受的亏损时，应该立即出场。 长期持仓时，如预期市场走出B1模式，不应轻易做空，尤其是在左侧交易时更应小心。 在左侧交易中，不应仅因为成本为负就立即操作，需关注市场信号，避免过早操作。 市场时机: 期货与期权挂钩: 买入暂时逆势上涨，而整体市场处于弱势时，可以考虑期货和期权的互动关系。 注意市场长期趋势，例如人民币汇率预测，在特朗普上台前，人民币可能不一定升值，长线来看，可能保持在一个波动区间内。 行业与个股选择: 几个特定行业如房地产和银行股应慎重考虑市场环境的影响。 成都等地的房地产市场较为稳健，考虑到土地成本等因素，选择区域内的购房策略。 技术分析: 关注换手率和成交量，可以透过趋势分析判断市场动向，如连续大成交量一般表示市场有较大波动在酝酿。 量化策略: 当市场进入稳定区间时，可以根据量化模型做出适当调整，如金价走势可能随美国政策波动加大，可预料会在区间内震荡。 股票投资心理: 保持理性和耐心，不要试图预判大盘走势，而是遵从市场变化的操作准则。 投资者应当依据自身风险承受能力和投资经验，选择适合的财报分析和投资模式。 投资建议: 建议关注个人的长期需求和市场实际情况进行投资。 私域好友可以通过合理私募理财策略，提升关注者的风险感知及动作执行能力，通过与高质量网红或机构合作，挖掘更多潜在客户。 注意投资者动向，把握政策导向及市场预期，适当调整操作计划，实现稳健增值。 这段内容涉及多个方面的问题，主要总结如下： 生日祝福与星座配对： 卡小呆z哥帅，今天过生日，有求生日祝福。 射手男和处女座的女人通常不合适，射手男倾向于直男大咧，而处女座注重细节。相比起来，射手男和狮子女比较合适。 星座相配讲解： 天蝎座天生适合射手座。 处女座和射手男之间不冲突，但处女座注重细节，射手男可能不太细致。 投资建议： 建议卖出密云的房产，并在顺义买新盘。 关于工作地点选择，建议不要在上海郊区买住宅，而是可以考虑苏州、深圳、成都是更好的选择。 情感情感建议： 处女男和摩羯女相处建议是保持稳定，互相支持。 处女男难以搞定射手女，建议直接表白，不磨叽。 职业建议： 想入行明星造型师，建议先通过美发店的培训做起，逐步积累经验。 购房建议： 寄托率高的东三环老破小更看重租金，而不是自身价值。 教学与分享： 创业和工作选择，保持理性，不要焦虑或行动过早。 推荐学习各种市场策略和心态调整，如写周记来保持专注。 总结来说，这段内容涵盖了的感情、星座配对、个人职业发展、购房建议等方面的问题，提供了相应的个性化指导。 [2024-11-25 02-38-31][zettaranc][如何备战第二阶段（11.24晚8开）].aac 以下是提取出的股票相关干货内容： 券商板块： 券商整体问题不大，因为它是业绩最确定的板块。 创业板指数太多，调整就属于正常现象，无需过度紧张。 认为现在并不是券商短期能够指望利润增长的时候。 投资建议： 提醒直播间里的粉丝，经济均衡发展是一个长期过程，不要对楼市抱有过高期望，可能长期仍处于震荡调整中。 建议投资者持续关注市场，不要轻易放弃，尤其是当前经济形势不确定的情况下。 短线操作需注意中长线止损，避免频繁操作导致资金受损。 具体购房建议： 告诫粉丝，哈尔滨及东北地区房产虽然价格稳定，但流动性较低，建议随时考虑入手而非盲目等待过高涨幅。 提及大学生恋爱中的实际问题，给出了具体的建议，例如通过送礼和创setup增强好感。 关于投资心理状态的指导： 坚持为好，尤其是在市场调整期要与企业共命运，长期持仓理解企业前进方向。 避免他人负面言论影响自己的投资信心，保持正能量，继续学习和关注市场。 总结来说，主播通过直播提示了一些投资上的重要信息，并为听众提供了实际操作方面的建议。 这段内容是一串互联网直播平台的聊天记录，涉及多个梗、星座、 astrology 相关的话题以及一些小段子和建议。主要内容包括但不限于以下几点： 讨论不同星座组合的配对建议，强调某些星座的特点及需要注意的地方。 关注某位名为“冷月妹妹”的网友，讨论其是否为真粉丝。 对粉丝提问进行回答，包括恋爱建议、星座配对和股票投资等方面的建议。 提醒一些操作注意事项，如不要沉迷假新闻、避免虚假宣传等。 在聊天过程中，参与者展示了对星座、股票等话题的兴趣，并分享了一些个人经验，如股票交易、相亲技巧等。 整段聊天记录充满幽默且感性，体现了社交媒体中的日常互动和娱乐性。 [2024-11-25 03-38-31][zettaranc][如何备战第二阶段（11.24晚8开）].aac 以下是提取出的股票相关干货内容： 止盈操作： “对，没错，该止盈了啊，不看了，不再check了。” “该止盈，今天就不再验证，了结结束这一趴结束啊。” 市场分析： “自己把自己化身成成这个女性，已经有人在对岛拉升，除非是行情的后期了，对吧？有点力不从心了，所以行，见好就收出货啊。” 投资建议： “一个三四线城市，五六线城市的小牌子，我们要按照LV的这种方式做代扣。你给我做一个，哎，不不来活了吗？做一个小红车，一圈呢，俩三四就都来了。” “李小葵妹妹，不是拿大号发的，你们别再发了，小心被人割韭菜。” 股票走势分析： “因为为什么你没发现，现在有点强弩之末了吗？发现了吗？就是已经没有没有那种酷哭，当时往上这种那种势能了，到最后已经有两个有两个已经开始这个在对岛拉升了。” 经济环境与消费： “到后面再等了一些好的标的就行了，它如果大跌一次，它离不开主线。不要判断底部在哪，你判断不了啊。” 市场策略： “你们要注意自己每一个交易的进步点的位置。就是说你现在已经学会在b一买了，哎，就说明你已经不再追高了，这已经是一个巨大的进步了。” “你有看到突破库，噗往上走，现在做不了四点了，睡不着啊，这个还在。” 这些信息浓缩了股票投资和市场策略的相关内容，希望对你有所帮助。 这段文字内容复杂，涉及多人的互动和一些网络社群的独特交流方式。以下是对主要内容的总结： 女粉验真与互动： 参与者讨论了各自女粉的身份验证，包括删除和重新发送照片，确保观众只有真实女粉。 一些女粉的身份被官方认定，比如“种子妹妹”、“藤椒妹妹”等，并有现场展示。 直播间的互动与交流： 参与者分享了自己对女粉的看法和交流，比如双子女特质的讨论。 提到一些男粉也参与，通过ID或备注方式确认女粉身份。 市场和投资话题： 有部分参与者谈论市场环境，投资策略，比如短期市场恐慌、追高后的止损策略。 建议通过积累经验分享和逐步积累粉丝，进入小红书等平台宣传活动经验。 其他信息： 再次强调了直播间的女粉构成，提到绝大多数是女粉，男粉在少数。 讨论了阶段性的营销策略，比如通过订阅或参与活动吸引潜在客户。 深夜讨论和休息提醒： 虽然讨论持续了一天，最终提醒大家注意休息，关注肌肤保养和护肤，合理安排时间和休息。 整个内容充满了网络社群特有的幽默、互动和营销策略，同时也探讨了现实生活中的一些现象。","categories":[],"tags":[]},{"title":"如何使用huggingface的trainer训练模型？","slug":"如何使用huggingface的trainer训练模型？","date":"2023-02-03T13:34:25.000Z","updated":"2024-11-26T16:26:22.004Z","comments":true,"path":"fcb5896c5f58.html","link":"","permalink":"http://chadqiu.github.io/fcb5896c5f58.html","excerpt":"","text":"huggingface上又很多开源模型，可以直接开箱即用，一个简单的模型使用实例如下： 1234567from transformers import BertTokenizer, BertModeltokenizer = BertTokenizer.from_pretrained(&#x27;uer/chinese_roberta_L-8_H-512&#x27;)model = BertModel.from_pretrained(&quot;uer/chinese_roberta_L-8_H-512&quot;)text = &quot;用你喜欢的任何文本替换我。&quot;encoded_input = tokenizer(text, return_tensors=&#x27;pt&#x27;)output = model(**encoded_input) 有时候，我们需要finetune自己的模型，通常使用pytorch代码训练，写起来比较复杂，如果使用huggingface的trainer来训练就很方便了。 训练一个NLU模型本文将使用trainer 训练一个牛客网讨论帖文本分类模型。详细过程如下： 构建数据集数据集下载链接：train datatest data正常的训练演示用这两个数据集就够了，如果需要训练很精确的模型，可以使用伪标签大数据集generated pesudo data数据集的结构如下：每条数据包含一个文本和一个label，label为： [招聘信息、 经验贴、 求助贴] 三种类型之一。我们需要加载数据集，并将文本tokenize成id，代码如下： 12345678910111213141516171819202122232425import pandas as pdfrom datasets import load_datasetfrom transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassificationmodel_name = &quot;bert-base-chinese&quot;max_input_length = 128label2id = &#123; &#x27;招聘信息&#x27;:0, &#x27;经验贴&#x27;:1, &#x27;求助贴&#x27;:2&#125;id2label = &#123;v:k for k,v in label2id.items()&#125;tokenizer = AutoTokenizer.from_pretrained(model_name)def preprocess_function(examples): model_inputs = tokenizer(examples[&quot;text&quot;], max_length=max_input_length, truncation=True) labels = [label2id[x] for x in examples[&#x27;target&#x27;]] model_inputs[&quot;labels&quot;] = labels return model_inputsraw_datasets = load_dataset(&#x27;csv&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.csv&#x27;, &#x27;test&#x27;: &#x27;test.csv&#x27;&#125;)tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=raw_datasets[&#x27;train&#x27;].column_names) 定义评价指标函数评价指标metric用于evaluate的时候衡量模型的表现，这里使用f1 score 和 accuracy 12345678910111213141516171819import numpy as npfrom sklearn.metrics import f1_score, accuracy_score, classification_reportfrom transformers import EvalPredictiondef multi_label_metrics(predictions, labels, threshold=0.5): probs = np.argmax( predictions, -1) y_true = labels f1_micro_average = f1_score(y_true=y_true, y_pred=probs, average=&#x27;micro&#x27;) accuracy = accuracy_score(y_true, probs) print(classification_report([id2label[x] for x in y_true], [id2label[x] for x in probs])) # return as dictionary metrics = &#123;&#x27;f1&#x27;: f1_micro_average, &#x27;accuracy&#x27;: accuracy&#125; return metrics def compute_metrics(p: EvalPrediction): preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions result = multi_label_metrics(predictions=preds, labels=p.label_ids) return result 指定模型的训练参数加载模型，并构建TrainingArguments类，用于指定模型训练的各种参数第一个是训练保存地址为必填项，其他都是选填项 1234567891011121314151617181920from transformers import TrainingArguments, Trainerbatch_size = 64training_args = TrainingArguments( f&quot;/root/autodl-tmp/run&quot;, evaluation_strategy = &quot;epoch&quot;, save_strategy = &quot;epoch&quot;, learning_rate=2e-4, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, # gradient_accumulation_steps=2, num_train_epochs=10, save_total_limit=1, weight_decay=0.01, load_best_model_at_end=True, metric_for_best_model=metric_name, fp16=True,) 定义trainer并进行训练1234567891011trainer = Trainer( model, training_args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;test&quot;], tokenizer=tokenizer, compute_metrics=compute_metrics)trainer.train() # 开始训练 测试预测12345678910print(&quot;test&quot;)print(trainer.evaluate()) # 测试trainer.save_model(&quot;bert&quot;) #保存模型# 进行模型预测，并将预测结果输出便于观察predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;test&quot;])predictions = np.argmax(predictions, axis=-1)print(predictions)print(labels) 代码整合将上面代码整合到一起，结果如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import pandas as pdimport numpy as npfrom datasets import load_datasetfrom transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassificationfrom transformers import TrainingArguments, Trainerfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_reportfrom transformers import EvalPredictionimport evaluatemetric = evaluate.load(&quot;seqeval&quot;)model_name = &quot;uer/chinese_roberta_L-4_H-512&quot;tokenizer = AutoTokenizer.from_pretrained(model_name)max_input_length = 128label2id = &#123; &#x27;招聘信息&#x27;:0, &#x27;经验贴&#x27;:1, &#x27;求助贴&#x27;:2&#125;id2label = &#123;v:k for k,v in label2id.items()&#125;def preprocess_function(examples): model_inputs = tokenizer(examples[&quot;text&quot;], max_length=max_input_length, truncation=True) labels = [label2id[x] for x in examples[&#x27;target&#x27;]] model_inputs[&quot;labels&quot;] = labels return model_inputsraw_datasets = load_dataset(&#x27;csv&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.csv&#x27;, &#x27;test&#x27;: &#x27;test.csv&#x27;&#125;)tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=raw_datasets[&#x27;train&#x27;].column_names)def multi_label_metrics(predictions, labels, threshold=0.5): probs = np.argmax( predictions, -1) y_true = labels f1_micro_average = f1_score(y_true=y_true, y_pred=probs, average=&#x27;micro&#x27;) accuracy = accuracy_score(y_true, probs) print(classification_report([id2label[x] for x in y_true], [id2label[x] for x in probs])) # return as dictionary metrics = &#123;&#x27;f1&#x27;: f1_micro_average, &#x27;accuracy&#x27;: accuracy&#125; return metrics def compute_metrics(p: EvalPrediction): preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions result = multi_label_metrics(predictions=preds, labels=p.label_ids) return resultmodel = AutoModelForSequenceClassification.from_pretrained(model_name, # problem_type=&quot;multi_label_classification&quot;, num_labels=3, # id2label=id2label, # label2id=label2id )batch_size = 64metric_name = &quot;f1&quot;training_args = TrainingArguments( f&quot;/root/autodl-tmp/run&quot;, evaluation_strategy = &quot;epoch&quot;, save_strategy = &quot;epoch&quot;, learning_rate=2e-4, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, # gradient_accumulation_steps=2, num_train_epochs=10, save_total_limit=1, weight_decay=0.01, load_best_model_at_end=True, metric_for_best_model=metric_name, fp16=True,)trainer = Trainer( model, training_args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;test&quot;], tokenizer=tokenizer, compute_metrics=compute_metrics)trainer.train()print(&quot;test&quot;)print(trainer.evaluate())trainer.save_model(&quot;bert&quot;)predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;test&quot;])predictions = np.argmax(predictions, axis=-1)print(predictions)print(labels) 模型推理预测使用训练好的模型在其他数据集上推理预测，新数据集是从牛客网爬取的帖子信息,接近4万条，数据链接： historical_data数据截图如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455from transformers import AutoTokenizer, AutoModelForSequenceClassificationimport pandas as pdimport torchdata = pd.read_excel(&quot;historical_data.xlsx&quot;, sheet_name=0).fillna(&quot; &quot;)data[&#x27;text&#x27;] = data[&#x27;title&#x27;].apply(lambda x : str(x) if x else &quot;&quot;) + data[&#x27;content&#x27;].apply(lambda x : str(x) if x else &quot;&quot;)model_name = &quot;bert&quot;model = AutoModelForSequenceClassification.from_pretrained(model_name)tokenizer = AutoTokenizer.from_pretrained(model_name)if torch.cuda.is_available(): device = &quot;cuda:0&quot; model.half()else: device = &quot;cpu&quot;model = model.to(device)max_target_length = 128label2id = &#123; &#x27;招聘信息&#x27;:0, &#x27;经验贴&#x27;:1, &#x27;求助贴&#x27;:2&#125;id2label = &#123;v:k for k,v in label2id.items()&#125;def get_answer(text): text = [x for x in text] inputs = tokenizer( text, return_tensors=&quot;pt&quot;, max_length=max_target_length, padding=True, truncation=True) inputs = &#123;k:v.to(device) for k,v in inputs.items()&#125; with torch.no_grad(): outputs = model(**inputs).logits.argmax(-1).tolist() return outputs# print(get_answer(data[&#x27;text&#x27;][:10]))pred , grod = [], []index, batch_size = 0, 32while index &lt; len(data[&#x27;text&#x27;]): pred.extend(get_answer([x for x in data[&#x27;text&#x27;][index:index + batch_size]])) index += batch_size# print(pred)# print(grod)pred = [id2label[x] for x in pred]data[&quot;target&quot;] = predwriter = pd.ExcelWriter(&quot;generate.xlsx&quot;)data.to_excel(writer, index=False, encoding=&#x27;utf-8&#x27;, sheet_name=&#x27;Sheet1&#x27;)writer.save()writer.close() 训练seq2seq生成式模型T5上面的例子是判别式模型，只用到了encoder，接下来训练一个encoder-decoder base的生成式模型T5，使用prompt用于训练，prompt方式如下： 123456789input:请问下面文本属于哪一类帖子？秋招大结局（泪目了）。家人们泪目了，一波三折之后获得的小奖状，已经准备春招了，没想到被捞啦，嗐，总之是有个结果，还是很开心的[掉小珍珠了][掉小珍珠了]选项：招聘信息, 经验贴, 求助贴答案：output:经验贴 构建数据集1234567891011121314151617181920212223242526from datasets import load_dataset, load_metricfrom transformers import AutoModelForSeq2SeqLM, T5Tokenizermodel_name = &quot;ClueAI/ChatYuan-large-v1&quot;model = AutoModelForSeq2SeqLM.from_pretrained(model_name)tokenizer = T5Tokenizer.from_pretrained(model_name)max_input_length = 128max_target_length = 20prefix = &quot;请问下面文本属于 招聘信息、 经验贴、 求助贴 三者中的哪一类？\\n&quot;suffix = &quot;\\n选项：招聘信息, 经验贴, 求助贴\\n答案：&quot;def preprocess_function(examples): inputs = [prefix + doc + suffix for doc in examples[&quot;text&quot;]] model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True) # Setup the tokenizer for targets with tokenizer.as_target_tokenizer(): labels = tokenizer(examples[&quot;target&quot;], max_length=max_target_length, truncation=True) model_inputs[&quot;labels&quot;] = labels[&quot;input_ids&quot;] return model_inputsraw_datasets = load_dataset(&#x27;csv&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.csv&#x27;, &#x27;test&#x27;: &#x27;test.csv&#x27;&#125;)tokenized_datasets = raw_datasets.map(preprocess_function, batched=True) 等一评价指标这次使用不一样的方式来构建评价指标 123456789101112import evaluatemetric = evaluate.load(&quot;seqeval&quot;)def compute_metrics(eval_pred): predictions, labels = eval_pred decoded_preds = [tokenizer.batch_decode(predictions, skip_special_tokens=True)] # Replace -100 in the labels as we can&#x27;t decode them. labels = np.where(labels != -100, labels, tokenizer.pad_token_id) decoded_labels = [tokenizer.batch_decode(labels, skip_special_tokens=True)] return metric.compute(predictions=decoded_preds, references=decoded_labels) 构建trainer训练12345678910111213141516171819202122232425262728293031323334from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainerbatch_size = 4args = Seq2SeqTrainingArguments( f&quot;yuan-finetuned-xsum&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=5e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size * 10, weight_decay=0.01, save_total_limit=3, num_train_epochs=3, predict_with_generate=True, # fp16=True, # push_to_hub=True,)data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)trainer = Seq2SeqTrainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;test&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics)trainer.train()print(&quot;test&quot;)print(trainer.evaluate()) 代码整合123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172import pandas as pdimport numpy as npfrom datasets import load_dataset, load_metricfrom transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainerfrom transformers import AutoModelForSeq2SeqLM, T5Tokenizerimport evaluatemetric = evaluate.load(&quot;seqeval&quot;)def compute_metrics(eval_pred): predictions, labels = eval_pred decoded_preds = [tokenizer.batch_decode(predictions, skip_special_tokens=True)] # Replace -100 in the labels as we can&#x27;t decode them. labels = np.where(labels != -100, labels, tokenizer.pad_token_id) decoded_labels = [tokenizer.batch_decode(labels, skip_special_tokens=True)] return metric.compute(predictions=decoded_preds, references=decoded_labels)model_name = &quot;ClueAI/ChatYuan-large-v1&quot;model = AutoModelForSeq2SeqLM.from_pretrained(model_name)tokenizer = T5Tokenizer.from_pretrained(model_name)max_input_length = 252max_target_length = 20batch_size = 4prefix = &quot;请问下面文本属于 招聘信息、 经验贴、 求助贴 三者中的哪一类？\\n&quot;suffix = &quot;\\n选项：招聘信息, 经验贴, 求助贴\\n答案：&quot;def preprocess_function(examples): inputs = [prefix + doc + suffix for doc in examples[&quot;text&quot;]] model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True) # Setup the tokenizer for targets with tokenizer.as_target_tokenizer(): labels = tokenizer(examples[&quot;target&quot;], max_length=max_target_length, truncation=True) model_inputs[&quot;labels&quot;] = labels[&quot;input_ids&quot;] return model_inputsraw_datasets = load_dataset(&#x27;csv&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.csv&#x27;, &#x27;test&#x27;: &#x27;test.csv&#x27;&#125;)tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)args = Seq2SeqTrainingArguments( f&quot;yuan-finetuned-yuan&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=5e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size * 10, weight_decay=0.01, save_total_limit=3, num_train_epochs=3, predict_with_generate=True, fp16=True)data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)trainer = Seq2SeqTrainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;test&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics)trainer.train()print(&quot;test&quot;)print(trainer.evaluate())trainer.save_model(&quot;yuan&quot;) 模型推理预测1234567891011121314151617181920212223242526272829303132333435363738from transformers import AutoModelForSeq2SeqLM, T5Tokenizerimport pandas as pdimport torchdata = pd.read_excel(&quot;historical_data.xlsx&quot;, sheet_name = 0).fillna(&quot; &quot;)data[&#x27;text&#x27;] = data[&#x27;title&#x27;].apply(lambda x : str(x) if x else &quot;&quot;) + data[&#x27;content&#x27;].apply(lambda x : str(x) if x else &quot;&quot;)model_name = &quot;yuan&quot;max_target_length = 512model = AutoModelForSeq2SeqLM.from_pretrained(model_name)tokenizer = T5Tokenizer.from_pretrained(model_name)if torch.cuda.is_available(): device = &quot;cuda:0&quot; model.half()else: device = &quot;cpu&quot;model = model.to(device)prefix = &quot;请问下面文本属于 招聘信息、 经验贴、 求助贴 三者中的哪一类？\\n&quot;suffix = &quot;\\n选项：招聘信息, 经验贴, 求助贴\\n答案：&quot;def get_answer(text): if not text : return &quot;&quot; inputs = tokenizer( prefix + str(text) + suffix, return_tensors=&quot;pt&quot;, max_length=max_target_length, truncation=True) inputs = &#123;k:v.to(device) for k,v in inputs.items()&#125; # print(inputs) outputs = model.generate(**inputs, max_new_tokens=5, return_dict_in_generate=True) return tokenizer.decode(outputs[0][0], skip_special_tokens=True)data[&#x27;target&#x27;] = data[&#x27;text&#x27;].map(get_answer) # not recommend, it&#x27;s better to generate in batches writer = pd.ExcelWriter(&quot;generate.xlsx&quot;)data.to_excel(writer, index=False, encoding=&#x27;utf-8&#x27;, sheet_name=&#x27;Sheet1&#x27;)writer.save()writer.close()","categories":[{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/categories/AI/"}],"tags":[{"name":"huggingface","slug":"huggingface","permalink":"http://chadqiu.github.io/tags/huggingface/"},{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"NLP","slug":"NLP","permalink":"http://chadqiu.github.io/tags/NLP/"},{"name":"train","slug":"train","permalink":"http://chadqiu.github.io/tags/train/"}]},{"title":"如何构建一个自定义huggingface dataset数据集？","slug":"huggingface的dataset如何自定义数据集？","date":"2023-02-03T04:37:34.000Z","updated":"2024-11-26T16:26:22.003Z","comments":true,"path":"6fcf23854660.html","link":"","permalink":"http://chadqiu.github.io/6fcf23854660.html","excerpt":"","text":"huggingface dataset中又很多开源数据集，使用起来非常方便，加载数据集代码如下所示。 1234from datasets import load_datasetdataset = load_dataset(&quot;glue&quot;, &quot;ax&quot;) 有时，我们希望使用自己的数据集，又与huggingface代码兼容，那就要自己构建一个dataset了。通常我们的数据是放在csv或excel表格中，通过pandas读取，那如何把表格数据转化为dataset呢？ csv文件或json文件，直接使用load_dataset 123456789from datasets import load_datasetimport pandas as pddataset = load_dataset(&quot;csv&quot;, data_files=&quot;my_file.csv&quot;)dataset = load_dataset(&#x27;csv&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.csv&#x27;, &#x27;test&#x27;: &#x27;test.csv&#x27;&#125;)dataset = load_dataset(&quot;json&quot;, data_files=&quot;my_file.json&quot;)dataset = load_dataset(&#x27;json&#x27;, data_files=&#123;&#x27;train&#x27;: &#x27;train.json&#x27;, &#x27;test&#x27;: &#x27;test.json&#x27;&#125;) 通过DatasetDict与from_pandas分别构建 123456789101112import pandas as pdfrom datasets import Dataset, DatasetDict train = Dataset.from_pandas(pd.read_csv(&#x27;train_spam.csv&#x27;))test = Dataset.from_pandas(pd.read_csv(&#x27;test_spam.csv&#x27;)) dataset = DatasetDict()dataset[&#x27;train&#x27;] = traindataset[&#x27;test&#x27;] = test 通过python的 dict、list、generator构建 123456789101112131415from datasets import Dataset# dictmy_dict = &#123;&quot;a&quot;: [1, 2, 3]&#125;dataset = Dataset.from_dict(my_dict)# listmy_list = [&#123;&quot;a&quot;: 1&#125;, &#123;&quot;a&quot;: 2&#125;, &#123;&quot;a&quot;: 3&#125;]dataset = Dataset.from_list(my_list)# generatordef my_gen(): for i in range(1, 4): yield &#123;&quot;a&quot;: i&#125;dataset = Dataset.from_generator(my_gen)","categories":[{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/categories/AI/"}],"tags":[{"name":"huggingface","slug":"huggingface","permalink":"http://chadqiu.github.io/tags/huggingface/"},{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"dataset","slug":"dataset","permalink":"http://chadqiu.github.io/tags/dataset/"},{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/tags/AI/"}]},{"title":"如何从零开始构建一个网络讨论帖分类模型？","slug":"如何从零开始构建一个网络讨论帖分类模型","date":"2023-02-03T00:56:52.000Z","updated":"2024-11-26T16:26:22.004Z","comments":true,"path":"9244fc05ea6b.html","link":"","permalink":"http://chadqiu.github.io/9244fc05ea6b.html","excerpt":"","text":"Motivation前几天搭建了一个对牛客网每天最新的工作信息进行爬取的程序，见牛客网爬虫，但从网上爬取下来的帖子有很多不是工作信息，需要把这部分干扰信息给排除掉，否则很影响使用心情。之前使用关键词与正则表达式进行了简单过滤，但总是有一些漏网之鱼，且容易误伤，如果能训练一个NLP分类模型来进行过滤，那就再好不过了，正好本人的研究方向是NLP，就想试着构建一个模型玩玩了。 数据准备但一般情况下要训练一个NLP模型需要几千到几万条有标注好的数据，而本项目没有现成的数据，这也是构建模型最困难的地方了。通过爬虫，获取了4万条左右的历史数据，包含id、用户昵称、标题、正文等内容，如下图所示，但没有标签。通过观察，可以把这些帖子大致分成 【招聘信息、经验贴、求助帖】三类，接下来就该考虑如何进行标注了。 人工标注太费时费力了，而且非常的不优雅，我们还是希望找到一个自动标注的方法，这里首先想到的就是最近两年在学术界比较火的few-shot、zero-shot技术了，且一般模型越大，效果越好。目前能访问到的大模型有： openAI的GPT3及最近大火的chatGPT，百度文心的 ERNIE 3.0大模型，已经一些机构开源在huggingface 和 魔搭社区的大模型，我使用prompt进行了一轮zero-shot尝试。prompt格式示例如下： 12345678请问下面文本属于 招聘信息、 经验贴、 求助贴 三者中的哪一类？秋招大结局（泪目了）。家人们泪目了，一波三折之后获得的小奖状，已经准备春招了，没想到被捞啦，嗐，总之是有个结果，还是很开心的[掉小珍珠了][掉小珍珠了]请问下面文本属于哪一类帖子？秋招大结局（泪目了）。家人们泪目了，一波三折之后获得的小奖状，已经准备春招了，没想到被捞啦，嗐，总之是有个结果，还是很开心的[掉小珍珠了][掉小珍珠了]选项：招聘信息, 经验贴, 求助贴答案： 经过一轮测试，发现他们的效果如下： chatGPT &gt; 百度文心 &gt;&gt; otherschatGPT表现较好，绝大本分都预测的比较准确，百度文心也基本可用，大部分都能答正确，之后就准备使用API来调用这两个大模型来标数据了，但百度文心每天只能访问200次，我很快超出次数限制，现阶段还不能直接付费购买服务，只能填合作申请表，然后等待。chatGPT不对中国用户开放，无法直接注册账户，通过特殊方法也是可以注册上的。前段时间翻墙后还能正常访问chatGPT的页面，但现在访问不了了，API在国内也访问不了，但可以采用“东数西算”的思想，把数据拿到国外的服务器上计算就行了，最简单的方法就是使用google的colab，免费创建一个notebook，并把数据传到google drive 或 GitHub，然后访问openAI的api。调用api需要先到官网上申请一个API key，然后再调用，使用pyhton调用API的代码如下： 12345678910111213141516171819import openaiopenai.api_key = &quot;your api key&quot;s = &#x27;&#x27;&#x27;请问下面文本属于哪一类帖子？viv0社招。 #春招# 有匹配岗位 有意向大佬欢迎＋微g1r4ffe内推 ...viv0社招开启，岗位多多hc多多。博士应聘专家岗位有1年以上工作经验即可 #社招#选项：招聘信息, 经验贴, 求助贴答案：&#x27;&#x27;&#x27;rst = openai.Completion.create( model=&quot;text-davinci-003&quot;, prompt= s, max_tokens=15, temperature=0)print(rst[&#x27;choices&#x27;][0][&quot;text&quot;])# output: 招聘信息 直接进去还没有chatGPT的API，但有 text-davinci-003 这一强大的模型，它基于GPT3大模型，使用了跟chatGPT相似的instruction训练，亲测效果很好，跟chatGPT差不多，甚至可以说就是chatGPT了。最终，用API标注了500条左右的数据，然后又人工标注了100条数据作为测试集。 模型与训练训练的基本策略为使用伪标签技术，即先使用少量数据训练一个模型，让这个模型去标数据，然后用其标注的数据集进行训练，最后结果往往会超过原来那个标注的模型。由于500条数据仍然很小，属于few-shot的范围了，因此希望使用尽量大的模型，一般模型越大，表现往往越好，大模型的few-shot能力也强，我在AutoDL上租了个24GB显存的A5000GPU，最大也就能训练1.3B大小的模型，但经过一系列实验后发现，居然是roberta-large表现最好，在我那个100数据的小测试集上F1 score超过了90%，然后用它对剩下的3万多条数据进行预测，生成标注数据集，最后使用该数据集训练一个新模型。由于后期要在cpu上运行，因此希望使用尽量小的模型，这里选择了腾讯的 uer&#x2F;chinese_roberta_L-4_H-512 模型进行训练，训练结果出人意料的好(也许是测试集太小，不准确)，如下图所示： 训练完成后的模型在roberta4h512文件夹中，可通过huggingface本地读取，读取示例如下： 12345from transformers import AutoTokenizer, AutoModelForSequenceClassificationmodel_name = &quot;roberta4h512&quot;model = AutoModelForSequenceClassification.from_pretrained(model_name)tokenizer = AutoTokenizer.from_pretrained(model_name) 模型训练代码： bert_train.py使用训练好的模型进行伪标签数据生成的代码：predict.py模型训练细节见 如何使用huggingface的trainer训练模型？ 预测过滤我们把爬回来的帖子中预测为招聘信息的帖子留下来，其他的过滤掉即可。爬虫程序一天执行一次，可以采用类似懒加载的方式加载模型，为了性能，需要分batch进行计算, 实测在cpu下183条数据需要6.5s左右，平均每条数据推理时间在36ms左右。预测代码如下： 1234567891011121314151617181920from transformers import AutoTokenizer, AutoModelForSequenceClassificationdef _batch_generate(texts, model, tokenizer, id2label = &#123;0: &#x27;招聘信息&#x27;, 1: &#x27;经验贴&#x27;, 2: &#x27;求助贴&#x27;&#125;, max_length = 128): inputs = tokenizer( texts, return_tensors=&quot;pt&quot;, max_length=128, padding=True, truncation=True) outputs = model(**inputs).logits.argmax(-1).tolist() return [id2label[x] for x in outputs]def model_predict(text_list, model = None, tokenizer = None, model_name = &quot;roberta4h512&quot;, batch_size = 4): if not text_list: return [] if not model: model = AutoModelForSequenceClassification.from_pretrained(model_name) if not tokenizer: tokenizer = AutoTokenizer.from_pretrained(model_name) model.eval() result, start = [], 0 while(start &lt; len(text_list)): result.extend(_batch_generate(text_list[start : start + batch_size], model, tokenizer)) start += batch_size return result 使用示例如下： 12345678910ss = [ &#x27;秋招大结局（泪目了）。家人们泪目了，一波三折之后获得的小奖状，已经准备春招了，没想到被捞啦，嗐，总之是有个结果，还是很开心的[掉小珍珠了][掉小珍珠了]&#x27;, &#x27;找到工作之后还要继续找吗。5k 加班严重 春招还想继续找 大家有什么好的建议 #我的求职思考# ...双非应届本科 拿了一个广州嵌入式offer 待遇9.&#x27;]print(model_predict(ss))# output: [&#x27;经验贴&#x27;, &#x27;求助贴&#x27;] 项目guthub地址：https://github.com/chadqiu/newcoder-crawler","categories":[{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/categories/AI/"}],"tags":[{"name":"huggingface","slug":"huggingface","permalink":"http://chadqiu.github.io/tags/huggingface/"},{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/tags/AI/"},{"name":"NLP","slug":"NLP","permalink":"http://chadqiu.github.io/tags/NLP/"}]},{"title":"二分搜索","slug":"二分搜索","date":"2023-01-27T17:59:16.000Z","updated":"2024-11-26T16:26:22.003Z","comments":true,"path":"79bdc4d1f745.html","link":"","permalink":"http://chadqiu.github.io/79bdc4d1f745.html","excerpt":"","text":"概述二分搜索主要思想：在有序数组nums的给定搜索区间[left, right]中搜索答案target，每一次搜索比较nums[mid]与target，若相等则找到答案，若不等则可以排除掉一半区间，减少候选集的大小，注意mid要被排除在下一次搜索区间之外。 二分查找代码框架如下： 12345678910111213141516int binarySearch(int[] nums, int target) &#123; int left = 0, right = ...; while(...) &#123; int mid = left + (right - left) / 2; if (nums[mid] == target) &#123; ... &#125; else if (nums[mid] &lt; target) &#123; left = ... &#125; else if (nums[mid] &gt; target) &#123; right = ... &#125; &#125; return ...;&#125; 若nums = [1,2,2,2,3]，target = 2，如何用二分搜索方法找到target出现的左右边界？上面的代码框架包含了查找精确位置及查找左右边界，需要填充的部分的主要思想是保证搜索区间不能漏掉一个元素，也不能重复一个元素。 当搜索区间左右都是闭区间[left, right]的时候，具体代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152int binarySearch(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while (left &lt;= right)&#123; int mid = (right - left) / 2 + left; if (nums[mid] == target)&#123; return mid; &#125; else if (nums[mid] &lt; target)&#123; left = mid + 1; &#125; else if (nums[mid] &gt; target)&#123; right = mid - 1; &#125; &#125; return -1;&#125;int leftBound(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while (left &lt;= right)&#123; int mid = (right - left) / 2 + left; if (nums[mid] == target)&#123; right = mid - 1; &#125; else if (nums[mid] &lt; target)&#123; left = mid + 1; &#125; else if (nums[mid] &gt; target)&#123; right = mid - 1; &#125; &#125; if (left &lt; nums.length &amp;&amp; nums[left] == target) return left; return -1;&#125;int rightBound(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while (left &lt;= right)&#123; int mid = (right - left) / 2 + left; if (nums[mid] == target)&#123; left = mid + 1; &#125; else if (nums[mid] &lt; target)&#123; left = mid + 1; &#125; else if (nums[mid] &gt; target)&#123; right = mid - 1; &#125; &#125; if (right &gt;= 0 &amp;&amp; nums[right] == target) return right; return -1;&#125; 规律总结： 当 nums[mid] == target 时，精确查找直接return，边界查找将mid排除在查找区间之外，找左边界时缩小右边，找右边界时缩小左边；当 nums[mid] ！= target 时，将mid排除在下一次的查找区间之外。 对于边界查找，也可以使 right = nums.length， 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839int leftBound(int[] nums, int target) &#123; int left = 0; int right = nums.length; // 注意 while (left &lt; right) &#123; // 注意 int mid = left + (right - left) / 2; if (nums[mid] == target) &#123; right = mid; &#125; else if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid; // 注意 &#125; &#125; if (left &lt; nums.length &amp;&amp; nums[left] == target) return left; return -1;&#125;int rightBound(int[] nums, int target) &#123; int left = 0, right = nums.length; while (left &lt; right) &#123; int mid = left + (right - left) / 2; if (nums[mid] == target) &#123; left = mid + 1; // 注意 &#125; else if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid; &#125; &#125; if (right &gt;= 1 &amp;&amp; nums[right - 1] == target) return right - 1; // 注意 return -1;&#125; 此时搜索的区间是左闭右开区间[left, right)，while()中用的是&lt;而不是&lt;=，因为 [x, x)为空集当 nums[mid] == target 时，将mid排除在查找区间之外，找左边界时缩小右边，找右边界时缩小左边；当 nums[mid] ！= target 时，将mid排除在下一次的查找区间之外 规律总结 二分查找每次比较搜索区间的中点，当初始化 right = nums.length - 1 时搜索区间为闭区间[left, right]，初始化 right = nums.length 时搜索区间为左闭右开区间[left, right)，二者等效； while()中用的是 &lt; 还是 &lt;= 取决于当 left == right 时是否为空集, 确保不遗漏、不重复; 当 nums[mid] == target 时，精确查找直接return，边界查找将mid排除在查找区间之外，找左边界时缩小右边，找右边界时缩小左边； 当 nums[mid] != target 时，将mid排除在下一次的查找区间之外。","categories":[{"name":"计算机基础 - 数据结构与算法","slug":"计算机基础-数据结构与算法","permalink":"http://chadqiu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://chadqiu.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"二分搜索","slug":"二分搜索","permalink":"http://chadqiu.github.io/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"},{"name":"Java","slug":"Java","permalink":"http://chadqiu.github.io/tags/Java/"}]},{"title":"谷歌学术爬虫","slug":"谷歌学术爬虫","date":"2023-01-27T09:27:35.000Z","updated":"2024-11-26T16:26:22.004Z","comments":true,"path":"083653212f47.html","link":"","permalink":"http://chadqiu.github.io/083653212f47.html","excerpt":"","text":"一个针对谷歌学术(Google scholar)的爬虫，需要科学上网。支持根据关键词搜索相关的论文前N篇论文，获取论文的主要信息信息。 根据关键词搜索 可以指定：关键词、开始时间、结束时间、返回论文的数量（建议不超过200，否则容易被封），爬取的结果包括： [论文标题, 引用数, 发表时间及机构缩写, 论文链接]，见上图划线的部分结果会print出来，同时也会自动保存到一个excel文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from bs4 import BeautifulSoupimport urllib.requestimport reimport timeimport tracebackimport pandas as pdimport warningswarnings.filterwarnings(&quot;ignore&quot;)headers = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27; &#x27;Chrome/90.0.4430.93 Safari/537.36&#x27;&#125;def get_paper_page(url): req = urllib.request.Request(url=url, headers=headers) res = urllib.request.urlopen(req, timeout=100) html=res.read().decode(&#x27;utf-8&#x27;) soup=BeautifulSoup(html) data = [[div.select(&#x27;.gs_rt &gt; a&#x27;)[0].text, div.select(&#x27;.gs_fl &gt; a&#x27;)[2].string, re.search(&quot;- .*?\\&lt;/div&gt;&quot;, str(div.select(&#x27;.gs_a&#x27;)[0])).group()[1:-6].replace(&quot;\\xa0&quot;, &quot;&quot;), div.select(&#x27;.gs_rt &gt; a&#x27;)[0][&quot;href&quot;]] for div in soup.select(&#x27;.gs_ri&#x27;)] data = [[x[0], int(x[1][6:]) if x[1] != None and x[1].startswith(&quot;被引用次数&quot;) else 0, x[2], x[3]] for x in data] return datadef save_paper_list(data, file_name): data = pd.DataFrame(data, columns=[&#x27;paper title&#x27;, &#x27;reference&#x27;, &#x27;publish info&#x27;, &#x27;url&#x27;]) writer = pd.ExcelWriter(file_name) data.to_excel(writer, index=False, encoding=&#x27;utf-8&#x27;, sheet_name=&#x27;Sheet1&#x27;) writer.save() writer.close()def get_paper_list_by_keywork(keyword, start_year = None, end_year = None, max_capacity = 100, debug_mode = False, save_file = &quot;paper_list.xlsx&quot;, retry_times = 3): keyword = re.sub(&quot; +&quot;, &quot;+&quot;, keyword.strip()) url_base = &#x27;https://scholar.google.com/scholar?hl=zh-CN&amp;as_sdt=0%2C5&#x27; url_base = url_base + &#x27;&amp;q=&#x27; + keyword if start_year != None: url_base += &quot;&amp;as_ylo=&quot; + str(start_year) if end_year != None: url_base += &quot;&amp;as_yhi=&quot; + str(end_year) start = 0 data = [] while start &lt; max_capacity: url = url_base + &quot;&amp;start=&quot; + str(start) start += 10 print(url) for i in range(retry_times): try: data.extend(get_paper_page(url)) break except Exception as e: if i &lt; retry_times -1: print(&quot;error, retrying ... &quot;) else: print(&quot;error, fail to get &quot;, url) if debug_mode: traceback.print_exc() time.sleep(20) time.sleep(10) # data: [论文标题, 引用数, 发表时间及机构缩写, 论文链接] print(data) save_paper_list(data, save_file)if __name__ == &quot;__main__&quot;: get_paper_list_by_keywork(&quot; named entity recognition &quot;, start_year=2020, max_capacity=100, debug_mode=False, save_file = &quot;paper_list.xlsx&quot;) print(&quot;end&quot;) 爬取结果如下图所示：","categories":[{"name":"tools - 爬虫","slug":"tools-爬虫","permalink":"http://chadqiu.github.io/categories/tools-%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chadqiu.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"谷歌学术","slug":"谷歌学术","permalink":"http://chadqiu.github.io/tags/%E8%B0%B7%E6%AD%8C%E5%AD%A6%E6%9C%AF/"}]},{"title":"牛客网爬虫","slug":"牛客网爬虫","date":"2023-01-27T08:43:42.000Z","updated":"2024-11-26T16:26:22.004Z","comments":true,"path":"f06a19b2ce94.html","link":"","permalink":"http://chadqiu.github.io/f06a19b2ce94.html","excerpt":"","text":"爬取牛客网的帖子，获取一些感兴趣的信息，比如职位内推等。为获得每日最新数据，系统使用增量更新，老数据保存到mysql数据库中用于去重，使用NLP分类模型进行内容筛选，过滤掉无关内容，每日新增的数据发邮件提醒，使用crontab定时任务每天自动运行，邮件效果如下图所示: MySQL数据表结构如下12345678910CREATE TABLE IF NOT EXISTS `newcoder_search`( `id` BIGINT NOT NULL, `title` VARCHAR(40), `content` text NOT NULL, `user` VARCHAR(40) NOT NULL, `url` VARCHAR(60) NOT NULL, `created_time` datetime NOT NULL, `edited_time` datetime NOT NULL, PRIMARY KEY ( `id` ))ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; python爬虫爬取并解析数据 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import requestsimport jsonimport timeimport redef _parse_newcoder_page(data, skip_words, start_date): assert data[&#x27;success&#x27;] == True pattern = re.compile(&quot;|&quot;.join(skip_words)) res = [] for x in data[&#x27;data&#x27;][&#x27;records&#x27;]: x = x[&#x27;data&#x27;] dic = &#123;&quot;user&quot;: x[&#x27;userBrief&#x27;][&#x27;nickname&#x27;]&#125; x = x[&#x27;contentData&#x27;] if &#x27;contentData&#x27; in x else x[&#x27;momentData&#x27;] dic[&#x27;title&#x27;] = x[&#x27;title&#x27;] dic[&#x27;content&#x27;] = x[&#x27;content&#x27;] dic[&#x27;id&#x27;] = int(x[&#x27;id&#x27;]) dic[&#x27;url&#x27;] = &#x27;https://www.nowcoder.com/discuss/&#x27; + str(x[&#x27;id&#x27;]) if len(skip_words) &gt; 0 and pattern.search(x[&#x27;title&#x27;] + x[&#x27;content&#x27;]) != None: #关键词正则过滤 continue createdTime = x[&#x27;createdAt&#x27;] if &#x27;createdAt&#x27; in x else x[&#x27;createTime&#x27;] dic[&#x27;createTime&#x27;] = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime(createdTime // 1000)) dic[&#x27;editTime&#x27;] = time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, time.localtime(x[&#x27;editTime&#x27;] // 1000)) if dic[&#x27;editTime&#x27;] &lt; start_date: # 根据时间过滤 continue res.append(dic) return resdef get_newcoder_page(page = 1, keyword = &quot;校招&quot;, skip_words = [], start_date = &#x27;2023&#x27;): header = &#123; &quot;user-agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&quot;, &quot;content-type&quot;:&quot;application/json&quot; &#125; data = &#123; &quot;type&quot;: &quot;all&quot;, &quot;query&quot;: keyword, &quot;page&quot;: page, &quot;tag&quot;: [], &quot;order&quot;: &quot;create&quot; &#125; x = requests.post(&#x27;https://gw-c.nowcoder.com/api/sparta/pc/search&#x27;, data = json.dumps(data), headers = header, ) data = _parse_newcoder_page(x.json(), skip_words, start_date) return data 数据落库去重将数据存入数据库，根据id去重，如果id不存在则insert，如果id已存在但editTime 有变化则update， 否则是重复的过滤掉 1234567891011121314151617181920212223242526272829import pymysqldef upsert_to_db(data, host, user, passwd, database,charset, port): db = pymysql.connect( host=host, user=user, passwd=passwd, database = database, charset=charset, port = port ) try: cursor = db.cursor() sql = &quot;select id, edited_time from newcoder_search where id in (&#123;&#125;)&quot;.format(&quot;,&quot;.join([str(x[&#x27;id&#x27;]) for x in data])) cursor.execute(sql) exists = cursor.fetchall() dic = &#123;x[0] : x[1].strftime(&quot;%Y-%m-%d %H:%M:%S&quot;) for x in exists&#125; insert_data = [[x[k] for k in x] for x in data if x[&#x27;id&#x27;] not in dic] update_data = [(x[&#x27;editTime&#x27;], x[&#x27;id&#x27;]) for x in data if x[&#x27;id&#x27;] in dic and dic[x[&#x27;id&#x27;]] != x[&#x27;editTime&#x27;]] sql = &quot;INSERT INTO newcoder_search (user, title, content, id, url, created_time, edited_time) VALUES(%s, %s, %s, %s, %s, %s, %s)&quot; cursor.executemany(sql, insert_data) sql = &quot;update newcoder_search set edited_time = %s where id = %s&quot; cursor.executemany(sql, update_data) db.commit() except Exception as e: print(&quot;db error: &quot;, e) db.close() return [x for x in data if x[&#x27;id&#x27;] not in dic], [x for x in data if x[&#x27;id&#x27;] in dic and dic[x[&#x27;id&#x27;]] != x[&#x27;editTime&#x27;]] 邮件发送将新创建的帖子与原有的但更改过的帖子区分开发送 1234567891011121314151617181920212223242526272829303132333435import smtplibfrom email.mime.text import MIMETextdef _table_html_generate(data): s = &#x27;&lt;table&gt;&#x27; s += &#x27;&lt;tr&gt;&#x27; + &quot;\\n&quot;.join([&quot;&lt;th&gt;&quot; + x + &#x27;&lt;/th&gt;&#x27; for x in data[0]]) + &#x27;&lt;/tr&gt;&#x27; for d in data: s += &#x27;&lt;tr&gt;&#x27; + &quot;\\n&quot;.join([&quot;&lt;td&gt;&quot; + str(d[x]) + &#x27;&lt;/td&gt;&#x27; for x in d]) + &#x27;&lt;/tr&gt;&#x27; s += &#x27;&lt;/table&gt;&#x27; return sdef send_email(insert_data, update_data, mail_host, mail_user, mail_pass, sender, receivers): msg = &#x27;&#x27; if len(insert_data) &gt; 0: msg += &#x27;&lt;h1&gt;insert&lt;/h1&gt;&lt;/br&gt;&#x27; + _table_html_generate(insert_data) + &#x27;&lt;/br&gt;&lt;/br&gt;&#x27; if len(update_data) &gt; 0: msg += &#x27;&lt;h1&gt;update&lt;/h1&gt;&lt;/br&gt;&#x27; + _table_html_generate(update_data) + &#x27;&lt;/br&gt;&lt;/br&gt;&#x27; if msg == &#x27;&#x27;: msg = &#x27;&lt;h1&gt;今日无新增数据&lt;/h1&gt;&lt;/br&gt;&#x27; message = MIMEText(msg, &#x27;html&#x27;, &#x27;utf-8&#x27;) message[&#x27;Subject&#x27;] = &#x27;牛客网&#123;&#125;招聘信息&#x27;.format(time.strftime(&quot;%Y-%m-%d&quot;)) message[&#x27;From&#x27;] = sender message[&#x27;To&#x27;] = receivers[0] try: smtpObj = smtplib.SMTP_SSL(mail_host, 465) #smtpObj.connect(mail_host, 465) smtpObj.login(mail_user, mail_pass) smtpObj.sendmail( sender, receivers, message.as_string()) smtpObj.quit() return True except smtplib.SMTPException as e: print(&#x27;email send error: &#x27;, e) return False 集成控制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657def run(keywords, skip_words, db_config, mail_config = None): res = [] for key in keywords: print(key, time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)) for i in range(1, 11): print(i) page = get_newcoder_page(i, key, skip_words) if not page: break res.extend(page) time.sleep(1) result, ids = [], set() # 去重 for x in res: if x[&#x27;id&#x27;] in ids: continue ids.add(x[&#x27;id&#x27;]) result.append(x) print(&quot;total num: &quot;, len(result)) x = upsert_to_db(result, **db_config) # insert_data, update_data if mail_config: send_email(*x, **mail_config)def main(): # 指定要过滤的词 skip_words=[&#x27;求捞&#x27;, &#x27;泡池子&#x27;, &#x27;池子了&#x27;, &#x27;池子中&#x27;, &#x27;offer对比&#x27;, &#x27;总结一下&#x27;, &#x27;给个建议&#x27;, &#x27;开奖群&#x27;, &#x27;没消息&#x27;, &#x27;有消息&#x27;, &#x27;拉垮&#x27;, &#x27;求一个&#x27;, &#x27;求助&#x27;, &#x27;池子的&#x27;, &#x27;决赛圈&#x27;, &#x27;offer比较&#x27;, &#x27;求捞&#x27;, &#x27;补录面经&#x27;, &#x27;捞捞&#x27;, &#x27;收了我吧&#x27;, &#x27;offer选择&#x27;, &#x27;有offer了&#x27;, &#x27;想问一下&#x27;, &#x27;kpi吗&#x27;, &#x27;kpi面吗&#x27;, &#x27;kpi面吧&#x27;] # 指定搜索的关键词 keywords = [&#x27;补招&#x27;, &#x27;补录&#x27;] #配置数据库信息 db_config = &#123; &quot;host&quot; : &quot;localhost&quot;, &quot;user&quot; : &quot;root&quot;, &quot;passwd&quot; : &quot;your password&quot;, &quot;database&quot; : &#x27;your database&#x27;, &quot;charset&quot; : &#x27;utf8&#x27;, &quot;port&quot;: your mysql port &#125; # 配置邮箱信息 mail_config = &#123; &quot;mail_host&quot; : &#x27;smtp server host&#x27;, &quot;mail_user&quot; : &#x27;your user name&#x27;, &quot;mail_pass&quot; : &#x27;password&#x27;, # 密码(部分邮箱为授权码) &quot;sender&quot; : &#x27;sender email&#x27;, &quot;receivers&quot; : [&quot;receivers email&quot;] &#125; run(keywords, skip_words, db_config, mail_config) if __name__ == &quot;__main__&quot;: main() print(&quot;end&quot;) 内容筛选直接爬下来的帖子既包含招聘信息，又包含求职者发布的面经、讨论贴等其他内容，现在希望过滤掉那些无关的帖子。第一版只写了一个根据关键词和正则表达式进行过滤的功能，用户指定skip_words，凡包含这里面的关键词的都会被过滤。过滤方法如下： 1234567import reskip_words = [&#x27;求捞&#x27;, &#x27;泡池子&#x27;, &#x27;兄弟们&#x27;, &#x27;姐妹们&#x27;, &#x27;家人们&#x27;, &#x27;狗都\\\\w&#123;0,2&#125;去&#x27;, &#x27;有推荐\\\\w&#123;0,5&#125;吗&#x27;, &#x27;选offer&#x27;, &#x27;交流一下&#x27;, &#x27;该怎么办&#x27;, &#x27;坐立不安&#x27;, &#x27;辗转难眠&#x27;, &#x27;哈哈哈&#x27;, &#x27;求支招&#x27;, &#x27;求经验&#x27;, &#x27;抱大腿&#x27;, &#x27;有没有\\\\w&#123;0,3&#125;懂&#x27;, &#x27;诈骗&#x27;, &#x27;毁约&#x27;, &#x27;秋招历程&#x27;, &#x27;求\\\\w&#123;0,5&#125;建议&#x27;, &#x27;二战&#x27;, &#x27;感觉有点悬&#x27;, &#x27;写给\\\\w&#123;0,10&#125;同学&#x27;, &#x27;好心人&#x27;, &#x27;一脸懵逼&#x27;, &#x27;纠结&#x27;, &#x27;有推荐\\\\w&#123;0,1&#125;的&#x27;, &#x27;如何准备&#x27;, &#x27;帮\\\\w&#123;0,1&#125;选一下&#x27;, &#x27;考研\\\\w&#123;0,2&#125;失败&#x27;, &#x27;求指导&#x27;, &#x27;开始了吗&#x27;, &#x27;秋招总结&#x27;, &#x27;校招总结&#x27;, &#x27;还有机会吗&#x27;, &#x27;池子了&#x27;, &#x27;池子中&#x27;, &#x27;offer对比&#x27;, &#x27;开奖群&#x27;, &#x27;拉垮&#x27;, &#x27;求一个&#x27;, &#x27;求助&#x27;, &#x27;池子的&#x27;, &#x27;决赛圈&#x27;, &#x27;offer比较&#x27;, &#x27;迷茫的人&#x27;, &#x27;年度总结&#x27;, &#x27;有没有友友&#x27;, &#x27;救救孩子&#x27;, &#x27;骂醒&#x27;, &#x27;问\\\\w&#123;0,2&#125;大佬&#x27;, &#x27;一般\\\\w&#123;0,4&#125;怎么找&#x27;, &#x27;考研人&#x27;, &#x27;求指导&#x27;, &#x27;求捞&#x27;, &#x27;补录面经&#x27;, &#x27;捞捞&#x27;, &#x27;收了我吧&#x27;, &#x27;offer选择&#x27;, &#x27;想问一下&#x27;, &#x27;kpi\\\\w&#123;0,1&#125;吗&#x27;, &#x27;kpi\\\\w&#123;0,1&#125;吧&#x27;]s = &quot;大佬们可以帮我看一下简历吗。 想参加春招，可以帮忙看一下简历吗 #如何看待2023届秋招# #简历# #春招提前批#...北京某末流211工商管理大类专业，没什么特别突出的经历，学校没有参加过大赛，&quot;pattern = re.compile(&quot;|&quot;.join(skip_words)) if pattern.search(s) != None: print(&quot;filter out this data&quot;) 但这种方法也不是很准，还是会有漏网之鱼，怎么才能实现更精准的过滤呢？一种可能的方案是训练一个NLP分类模型进行过滤，但这需要大量数据进行训练，目前我已爬取牛客网上历史数据4万多条，但需要标注数据，不太想人工去标数据，这个计划暂时搁置，代码和历史数据已开源在github newcoder-crawler**[更新]**：最后还是忍不住想玩一下，花了一周时间，训练了一个帖子分类模型进行过滤，详细构建过程见如何从零开始构建一个网络讨论帖分类模型？，模型地址:roberta4h512.zip.下载下来后解压，将roberta4h512文件夹放到与爬虫脚本同级目录下，模型推理的代码如下： 1234567891011121314151617181920from transformers import AutoTokenizer, AutoModelForSequenceClassificationdef _batch_generate(texts, model, tokenizer, id2label = &#123;0: &#x27;招聘信息&#x27;, 1: &#x27;经验贴&#x27;, 2: &#x27;求助贴&#x27;&#125;, max_length = 128): inputs = tokenizer( texts, return_tensors=&quot;pt&quot;, max_length=128, padding=True, truncation=True) outputs = model(**inputs).logits.argmax(-1).tolist() return [id2label[x] for x in outputs]def model_predict(text_list, model = None, tokenizer = None, model_name = &quot;roberta4h512&quot;, batch_size = 4): if not text_list: return [] if not model: model = AutoModelForSequenceClassification.from_pretrained(model_name) if not tokenizer: tokenizer = AutoTokenizer.from_pretrained(model_name) model.eval() result, start = [], 0 while(start &lt; len(text_list)): result.extend(_batch_generate(text_list[start : start + batch_size], model, tokenizer)) start += batch_size return result 最后，稍微改一下run函数，加入模型过滤的逻辑即可，另外还有一些人会把一个信息重复发布多份，这里加入一个根据内容进行去重的逻辑，修改后的run函数如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445def filter(data, unique_content, model = None, tokenizer = None): # 模型过滤，根据页面内容去重 labels = model_predict([(str(x[&#x27;title&#x27;]) if x[&#x27;title&#x27;] else &quot;&quot; ) + &quot;\\t&quot; + (str(x[&#x27;content&#x27;]) if x[&#x27;content&#x27;] else &quot;&quot; ) for x in data], model, tokenizer) result = [] for i, x in enumerate(data): if x[&#x27;content&#x27;] in unique_content or labels[i] != &quot;招聘信息&quot;: continue unique_content.add(x[&#x27;content&#x27;]) result.append(x) return result def run(keywords, skip_words, db_config, mail_config = None): res = [] for key in keywords: print(key, time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)) for i in range(1, 21): print(i) page = get_newcoder_page(i, key, skip_words, start_date = time.strftime(&quot;%Y-%m-%d&quot;, time.localtime(time.time() - 15 * 24 * 60 * 60))) if not page: break res.extend(page) time.sleep(1) res.sort(key = lambda x: len(x[&#x27;content&#x27;])) result, ids = [], set() # 根据id去重 for x in res: if x[&#x27;id&#x27;] in ids: continue ids.add(x[&#x27;id&#x27;]) result.append(x) print(&quot;total num: &quot;, len(result)) #print(result) insert_data, update_data = upsert_to_db(result, **db_config) if mail_config: unique_content, shared_model, shared_tokenizer = set(), None, None insert_data = filter(insert_data, unique_content, shared_model, shared_tokenizer) update_data = filter(update_data, unique_content, shared_model, shared_tokenizer) send_email(insert_data, update_data, **mail_config) 编写shell脚本，使用crontab自动运行代码希望每天运行一次， 如果每次都手动运行的话，使用体验就很不好了，最好是放在服务器中，弄个croontab定时任务，每天自动运行一次。把启动的命令写成shell脚本如下：shell脚本newcoder.sh内容如下： 123source /root/anaconda3/bin/activate basecd /root/chadqiu/crawlerpython newcoder.py &gt; server.log 2&gt;&amp;1 crontab配置123crontab -l # 查看已经存在的定时任务crontab -e #编辑/新加定时任务service crond restart #重启，是刚才的配置更改生效 这里crontab -e新加配置内容如下，每天18：30运行一次： 130 18 * * * bash /root/chadqiu/crawler/newcoder.sh cron配置语法规则：5个位置含义如下： 12 Minute Hour Day Month Dayofweek command分钟 小时 天 月 天每星期 命令 1234“*”代表取值范围内的数字,“/”代表”每”,“-”代表从某个数字到某个数字,“,”分开几个离散的数字 Nacos配置中心刚才的main函数里有很多配置需要写，特别是过滤词、接收邮箱列表等可能会经常改变，每改一次就得重新改代码非常麻烦，因此引入了Nacos注册中心，将keywords, skip_words, db_config, mail_config这四个配置变量放在Nacos中，这样就可以动态修改了，在Nacos中配置为json格式，如下图所示 代码稍作修改，加入一个get_config函数，并修改一下main函数，修改的代码如下： 1234567891011121314151617181920212223import nacosimport jsondef get_config(SERVER_ADDRESSES, NAMESPACE, GROUP): print(SERVER_ADDRESSES, NAMESPACE) client = nacos.NacosClient(SERVER_ADDRESSES, namespace=NAMESPACE) keywords = json.loads(client.get_config(&quot;newcoder.crawler.keywords&quot;, GROUP)) skip_words = json.loads(client.get_config(&quot;newcoder.crawler.skip_words&quot;, GROUP)) db_config = json.loads(client.get_config(&quot;newcoder.crawler.db_config&quot;, GROUP)) mail_config= json.loads(client.get_config(&quot;newcoder.crawler.mail_config&quot;, GROUP)) return keywords, skip_words, db_config, mail_configdef main(): SERVER_ADDRESSES = &quot;ip:port&quot; NAMESPACE = &quot;your namespace&quot; GROUP= &quot;your group&quot; run(*get_config(SERVER_ADDRESSES, NAMESPACE, GROUP))if __name__ == &quot;__main__&quot;: main() print(&quot;end&quot;) 将上面两份代码整合后的完整代码见 github","categories":[{"name":"tools - 爬虫","slug":"tools-爬虫","permalink":"http://chadqiu.github.io/categories/tools-%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chadqiu.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"牛客网","slug":"牛客网","permalink":"http://chadqiu.github.io/tags/%E7%89%9B%E5%AE%A2%E7%BD%91/"}]},{"title":"爬虫入门","slug":"爬虫入门","date":"2023-01-27T05:38:36.000Z","updated":"2024-11-26T16:26:22.004Z","comments":true,"path":"395c25595e33.html","link":"","permalink":"http://chadqiu.github.io/395c25595e33.html","excerpt":"","text":"爬虫可以模拟浏览器向网站发起请求，获取网站数据，代替人做一些重复性劳动。 常见的网站可分为： 前后端分离架构 和 前后端不分离架构。对于前后端分离架构，只要发送request，返回的数据一般是json格式，很好处理；对于前后端不分离的网站，只能获取其html页面，然后使用BeautifulSoup从中提取想要的内容。 有些网站有反爬机制，需要做一些额外配置，最常见的是加一个’User-Agent’，有些需要cookie等其他header信息。具体信息可使用浏览器的开发者工具查看，chrome浏览器的快捷键为 “ctrl + shift + i”，然后点击network, 重新发送请求，即可看到请求的具体参数，也可用postman测试需要哪些参数。 一个简单的request请求结构如下： 123456789# 导入 requests 包import requests# 发送请求x = requests.get(&#x27;https://www.sogou.com/web?query=上海&#x27;)# 返回网页内容print(x.text) 一些示例搜狗网页提取将搜索“上海”的结果页面保存到 “上海.html” 文件，设置了 “user-agent” 123456789101112import requestsheader = &#123; &quot;user-agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&quot;&#125;param = &#123; &quot;query&quot;: &quot;上海&quot;&#125;x = requests.get(&#x27;https://www.sogou.com/web&#x27;, params = param, headers = header)print(x.text)with open(&quot;上海.html&quot;, &#x27;w&#x27;, encoding = &quot;utf-8&quot;) as f: f.write(x.text) 调用百度翻译百度翻译采用了前后端分离架构，返回的结果是json，非常便于处理 123456789import requestsheader = &#123; &quot;user-agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&quot;&#125;data = &#123; &quot;kw&quot;: &quot;crawler&quot;&#125;x = requests.post(&#x27;https://fanyi.baidu.com/sug&#x27;, data = data, headers = header)print(x.json()) 豆瓣电影12345678910111213import requestsheader = &#123; &quot;user-agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36&quot;&#125;param = &#123; &#x27;type&#x27;: &#x27;24&#x27;, &#x27;interval_id&#x27;: &#x27;100:90&#x27;, &#x27;action&#x27;: &#x27;&#x27;, &#x27;start&#x27;: &#x27;40&#x27;, &#x27;limit&#x27;: &#x27;20&#x27;&#125;x = requests.get(&#x27;https://movie.douban.com/j/chart/top_list&#x27;, params = param, headers = header)print(x.json()) 谷歌学术需要科学上网 12345678910import urllib.request,urllib.errorfrom bs4 import BeautifulSoupheaders = &#123;&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) &#x27; &#x27;Chrome/90.0.4430.93 Safari/537.36&#x27;&#125;url = &#x27;https://scholar.google.com/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;as_ylo=2018&amp;q=zero-shot+NER&#x27;req = urllib.request.Request(url=url, headers=headers)res = urllib.request.urlopen(req, timeout=7)html=res.read().decode(&#x27;utf-8&#x27;)soup=BeautifulSoup(html,&quot;lxml&quot;)print(soup)","categories":[{"name":"tools - 爬虫","slug":"tools-爬虫","permalink":"http://chadqiu.github.io/categories/tools-%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chadqiu.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"Hexo 常用操作命令","slug":"hello-world","date":"2023-01-27T04:38:36.000Z","updated":"2024-11-26T17:01:04.027Z","comments":true,"path":"62a45a82a2f9.html","link":"","permalink":"http://chadqiu.github.io/62a45a82a2f9.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ npx hexo new &quot;My New Post&quot; More info: Writing Run server1$ npx hexo server More info: Server Generate static files1$ npx hexo generate More info: Generating Deploy to remote sites1$ npx hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/categories/AI/"},{"name":"计算机基础 - 数据结构与算法","slug":"计算机基础-数据结构与算法","permalink":"http://chadqiu.github.io/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"tools - 爬虫","slug":"tools-爬虫","permalink":"http://chadqiu.github.io/categories/tools-%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"huggingface","slug":"huggingface","permalink":"http://chadqiu.github.io/tags/huggingface/"},{"name":"python","slug":"python","permalink":"http://chadqiu.github.io/tags/python/"},{"name":"NLP","slug":"NLP","permalink":"http://chadqiu.github.io/tags/NLP/"},{"name":"train","slug":"train","permalink":"http://chadqiu.github.io/tags/train/"},{"name":"dataset","slug":"dataset","permalink":"http://chadqiu.github.io/tags/dataset/"},{"name":"AI","slug":"AI","permalink":"http://chadqiu.github.io/tags/AI/"},{"name":"算法","slug":"算法","permalink":"http://chadqiu.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"二分搜索","slug":"二分搜索","permalink":"http://chadqiu.github.io/tags/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2/"},{"name":"Java","slug":"Java","permalink":"http://chadqiu.github.io/tags/Java/"},{"name":"爬虫","slug":"爬虫","permalink":"http://chadqiu.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"谷歌学术","slug":"谷歌学术","permalink":"http://chadqiu.github.io/tags/%E8%B0%B7%E6%AD%8C%E5%AD%A6%E6%9C%AF/"},{"name":"牛客网","slug":"牛客网","permalink":"http://chadqiu.github.io/tags/%E7%89%9B%E5%AE%A2%E7%BD%91/"}]}